<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>忘lele</title>
  
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://gmle.github.io/"/>
  <updated>2017-11-16T03:44:28.072Z</updated>
  <id>http://gmle.github.io/</id>
  
  <author>
    <name>忘了</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>C++ Primer 读书笔记</title>
    <link href="http://gmle.github.io/2017/10/25/cpp_primer/"/>
    <id>http://gmle.github.io/2017/10/25/cpp_primer/</id>
    <published>2017-10-25T06:21:39.585Z</published>
    <updated>2017-11-16T03:44:28.072Z</updated>
    
    <content type="html"><![CDATA[<pre><code>做点什么吧</code></pre><a id="more"></a><h1 id="第一章-开始"><a href="#第一章-开始" class="headerlink" title="第一章 开始"></a>第一章 开始</h1><ul><li>最近感觉自己很浮躁，看看书让自己静下心。</li><li>我之前学过Java，对于C++这种面向对象的语言也有一定的了解</li><li>之前也模模糊糊的看过一点C++的东西，也不全面，我现在尝试以一个没有学过c语言的人去学习C++，并且拜读圣经，希望能得到不错的成果。</li><li>本书采用的C++版本为 C++11</li></ul><h2 id="编写一个简单的C-程序"><a href="#编写一个简单的C-程序" class="headerlink" title="编写一个简单的C++程序"></a>编写一个简单的C++程序</h2><ul><li>就像Java有程序入口一样，C++程序也有入口，它们的入口函数都是 <strong>main</strong> 函数。</li><li>在执行成程序的时候，系统会调用 <strong>main</strong> 来运行程序。</li></ul><p>Example：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> main&#123;</div><div class="line">  <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><p>我保留了Java的书写习惯，将起始的大括号放在了 main 函数的一行，当然我感觉这样写好看一些吧（也可能是习惯）。</p><p>这是一个C++里最简单的函数，这段代码的作用是返回给操作系统一个值：0 。</p><p>C++函数构成包括四个部分：</p><ul><li>返回类型<ul><li>main函数的返回值类型必须为 <strong>int</strong>，即整数类型。 int类型是一种内置类型。</li></ul></li><li>函数名<ul><li>主函数名字为main函数，自定义的函数名字可以自行取。</li></ul></li><li>参数列表<ul><li>本例中没有带有任何参数。</li></ul></li><li>函数体<ul><li>大括号括起来的语句块即为函数体，此函数体中只包含一条语句。</li><li>此语句是结束词函数的执行，并向调用者返回一个值；此返回值类型必须与函数的返回值类型相同</li></ul></li></ul><hr><blockquote><p>重要概念：类型</p></blockquote><pre><code>因为Java是从C++演变而来，所以对于类型也有很深的认识，因为没有学过C++，没有具体了解到C++的所有类型，不方便发表自己的看法。(其实类型好像没什么看法)类型是程序设计的最基本的概念之一，一种类型不仅仅定义了数据元素的内容，还定义了这类数据上可以进行的运算程序所处理的数据都保存在变量中，而每个变量都有自己的类型。</code></pre><hr><h3 id="编译、运行程序"><a href="#编译、运行程序" class="headerlink" title="编译、运行程序"></a>编译、运行程序</h3><pre><code>编写好程序之后 我们就需要去编译它。</code></pre><p>编译环境我用的是<a href="http://cmake.org" target="_blank" rel="external">CMake</a>；CMake的使用，我参考了这份资料<a href="http://pan.baidu.com/s/1hrC3Ale" target="_blank" rel="external">CMake实践</a></p><h2 id="输入输出"><a href="#输入输出" class="headerlink" title="输入输出"></a>输入输出</h2><p>C++并没有定义输入输出语句，但是它有一个全面的标准库(std)来提供IO机制以及其他操作。</p><h3 id="标准输入输出对象"><a href="#标准输入输出对象" class="headerlink" title="标准输入输出对象"></a>标准输入输出对象</h3><pre><code>本示例使用 iostream 库，iostream 库中包含两个基础类型 istream 和 ostream，分别表示输入流和输出流。‘流’想要表达的是：随着时间的推移，自复式顺序生成或者消耗的。</code></pre><p>标准库定义了四个IO对象。</p><ul><li><p>为了处理输入，我们使用一个名为<strong>cin</strong>的istream类型的对象。这个对象成为标准输入。</p></li><li><p>为了处理输出，我们使用一个名为<strong>cout</strong>的ostream类型的对象。这个对象成为标准输出。</p></li><li><p>为了处理警告和错误消息，我们使用一个名为<strong>cerr</strong>的ostream类型的对象，我们称之为标准错误</p></li><li>clog则用来输出程序运行时的一般性信息。</li></ul><p>一个使用 IO 库的程序<br>​<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> (iostream) <span class="comment">//告诉编译器我们要使用的库为 iostream</span></span></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">" Enter two numbers: "</span>&lt;&lt;<span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line"></div><div class="line">    <span class="keyword">int</span> v1 = <span class="number">0</span>, v2 = <span class="number">0</span>;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cin</span> &gt;&gt; v1 &gt;&gt; v2;</div><div class="line"></div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"The sum of "</span> &lt;&lt; v1 &lt;&lt; <span class="string">" and "</span> &lt;&lt; v2 &lt;&lt; <span class="string">" is "</span> &lt;&lt;v1+v2 &lt;&lt; <span class="string">" ."</span> &lt;&lt;<span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line"></div><div class="line">    <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><ul><li>#include (iostream) # 告诉编译器我们要使用的库为 iostream</li><li>std指代库iostream中的命名空间。</li><li>endl 则被称之为 操纵符 的特殊值，写入endl的效果是结束当前行。并将与设备关联的缓冲区(buffer)刷到设备中。</li><li>缓冲刷新操作可以保证截至到目前的所有输出都写入到输出流中。</li><li>如果在调试的时候，我们不应该去执行endl将它写入到缓冲区中，应该一直使这个输出流报纸刷新。</li></ul><h2 id="注释"><a href="#注释" class="headerlink" title="注释"></a>注释</h2><p>注释可以帮助人类读者理解带有注释的程序。在编译的时候，编译器会自动忽略注释。</p><p>Example：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> (iostream)</span></div><div class="line"><span class="comment">/**</span></div><div class="line"><span class="comment">  * 这是多行注释</span></div><div class="line"><span class="comment">  * 请注意 注释 界定符不能嵌套</span></div><div class="line"><span class="comment">  * </span></div><div class="line"><span class="comment">      */</span></div><div class="line">      <span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">" Enter two numbers: "</span>&lt;&lt;<span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line"></div><div class="line">    <span class="comment">// 这是单行注释。 </span></div><div class="line">    <span class="keyword">int</span> v1 = <span class="number">0</span>, v2 = <span class="number">0</span>;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cin</span> &gt;&gt; v1 &gt;&gt; v2;</div><div class="line">    </div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"The sum of "</span> &lt;&lt; v1 &lt;&lt; <span class="string">" and "</span> &lt;&lt; v2 &lt;&lt; <span class="string">" is "</span> &lt;&lt;v1+v2 &lt;&lt; <span class="string">" ."</span> &lt;&lt;<span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><p>运算符：</p><ul><li>(&lt;&lt;)    输出运算符</li><li>(&gt;&gt;)    输入运算符</li><li>(&lt;=)    小于等于</li><li>(&gt;=)    大于等于</li></ul><h2 id="控制流"><a href="#控制流" class="headerlink" title="控制流"></a>控制流</h2><p>字面意思：控制程序的运行路径。</p><h3 id="while语句"><a href="#while语句" class="headerlink" title="while语句"></a>while语句</h3><p>while语句会反复执行一段带吗，直到给定的条件为假为止。<br>Example：<br>​<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</div><div class="line"></div><div class="line">    <span class="keyword">int</span> sum = <span class="number">0</span>, val = <span class="number">1</span>;</div><div class="line"></div><div class="line">    <span class="keyword">while</span> (val &lt;= <span class="number">1000</span>) &#123;</div><div class="line">    <span class="comment">// 只要val的值小于10，循环就会持续执行，</span></div><div class="line">        sum += val;</div><div class="line">        <span class="comment">// 将sum+val赋值给sum</span></div><div class="line">        ++val;</div><div class="line">        <span class="comment">//val+1</span></div><div class="line">    &#125;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; sum &lt;&lt;<span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">    <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><p>复合赋值运算符：</p><ul><li>+=    将右侧的运算对象加到左侧运算对象上。</li></ul><p>前缀递增运算符</p><ul><li>++    前缀++可以作为左值来使用，将运算的对象+1</li></ul><h3 id="1-4-2-for语句"><a href="#1-4-2-for语句" class="headerlink" title="1.4.2 for语句"></a>1.4.2 for语句</h3><p>上个while例子中的循环条件检测变量，再循环体中增加变量的模式使用非常频繁，所以C++专门定义了第二种循环语句：<strong>for</strong>语句。</p><p>使用for语句重写从1加到10的程序：<br>Example：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span> </span>&#123;</div><div class="line">​    </div><div class="line">    <span class="keyword">int</span> num1 = <span class="number">0</span>, num2 = <span class="number">0</span>;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"输入 num1： "</span>&lt;&lt;<span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cin</span> &gt;&gt; num1;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"输入 num2： "</span>&lt;&lt;<span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">    </div><div class="line">    <span class="keyword">for</span> (<span class="built_in">std</span>::<span class="built_in">cin</span> &gt;&gt; num2; num2&gt;=num1; ++num1) &#123;</div><div class="line">        <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; num1 &lt;&lt;<span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><h3 id="读取数量不定的输入数据"><a href="#读取数量不定的输入数据" class="headerlink" title="读取数量不定的输入数据"></a>读取数量不定的输入数据</h3><p>如果我们预先不知道要对多少个数求和，这就需要不断读取数据直至没有新的数据输入为止。</p><p>​<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</div><div class="line">    <span class="keyword">int</span> sum = <span class="number">0</span>, value = <span class="number">0</span>;</div><div class="line"></div><div class="line">    <span class="keyword">while</span> (<span class="built_in">std</span>::<span class="built_in">cin</span> &gt;&gt; value)&#123;</div><div class="line">        sum += value; </div><div class="line">    &#125;</div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"sum is "</span> &lt;&lt; sum &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><p>因为 value定义为 int类型，所以如果你输入了别的类型的字符，就会导致判断失败，从而不会再次进行循环，然后返回你输入的值的和。</p><h3 id="1-4-4-if语句"><a href="#1-4-4-if语句" class="headerlink" title="1.4.4 if语句"></a>1.4.4 if语句</h3><p>与大多数语言一样，c++也提供了 <strong>if</strong>语句来支持条件执行。</p><p>Example：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span> <span class="params">()</span></span>&#123;</div><div class="line">    <span class="keyword">int</span> isnums = <span class="number">0</span>, nums = <span class="number">0</span>;</div><div class="line"></div><div class="line">    <span class="keyword">if</span> (<span class="built_in">std</span>::<span class="built_in">cin</span> &gt;&gt; isnums) &#123;</div><div class="line">        <span class="keyword">int</span> count = <span class="number">1</span>;</div><div class="line">        </div><div class="line">        <span class="keyword">while</span> (<span class="built_in">std</span>::<span class="built_in">cin</span> &gt;&gt; nums) &#123;</div><div class="line">            <span class="keyword">if</span> (isnums == nums) &#123;</div><div class="line">                ++count;</div><div class="line">            &#125;<span class="keyword">else</span> &#123;</div><div class="line">                <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"The "</span>&lt;&lt; isnums &lt;&lt; <span class="string">" occurs "</span>&lt;&lt; count &lt;&lt; <span class="string">" times."</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">                isnums = nums;</div><div class="line">                count = <span class="number">1</span>;</div><div class="line">            &#125;</div><div class="line">        &#125;</div><div class="line">        <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; <span class="string">"The "</span>&lt;&lt; isnums &lt;&lt; <span class="string">" occurs "</span>&lt;&lt; count &lt;&lt; <span class="string">" times."</span> &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><h2 id="类简介"><a href="#类简介" class="headerlink" title="类简介"></a>类简介</h2><p>在C++中，我们铜鼓哦定义一个类来定义自己的数据结构。一个类定义了一个类型以及与其关联的一组操作。<br>类机制就是C++最重要的特性之一。<br>实际上，C++最初的一个设计焦点上就是能定义使用上像内置类型一样自然的类类型。<br>为了使用类，我们需要了解三件事情。</p><ul><li>类名是什么</li><li>它是在哪儿定义的</li><li>它支持什么操作</li></ul><p>对于我们即将写的书店程序来说，假定我们的类名为<strong>Sales_item</strong>，头文件 <strong>Sales_item.h</strong>中已经定义了这个类。</p><h3 id="Sales-item类"><a href="#Sales-item类" class="headerlink" title="Sales_item类"></a>Sales_item类</h3><p><strong>Sales_item</strong> 类的作用是表示一本书的总销售额、售出册数和平均售价。我们现在不关心这些数据如何存储、如何计算。为了使用一个雷，我们不必关心它是如何实现的，只需要知道类对象可以执行什么操作<br>每个类实际上都定义了一个新的类型，其类型名就是类名。<br>因此，我们的<strong>Sales_item</strong>类定义了一个名为<strong>Sales_item</strong>的类型，与内置类型一样，我们可以定义类类型的变量。<br>Example:<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">Sales_item item;</div></pre></td></tr></table></figure></p><p>此语句是想表达item是一个<strong>Sales_item</strong>类型的对象，我们通常将 “item是一个<strong>Sales_item</strong>类型的对象” 简单说成 “一个<strong>Sales_item</strong>对象”或者更简单的说成“一个<strong>Sales_item</strong>”。</p><p>除了定义<strong>Sales_item</strong>类型的变量之外呢，我们还可以：</p><ul><li>调用一个名为isbn的函数从一个<strong>Sales_item</strong>对象中提取 ISBN 书号</li><li>用输入运算符（&gt;&gt;）和输出运算符（&lt;&lt;）读写<strong>Sales_item</strong>类型的对象。</li><li>用加法运算符（+）将两个<strong>Sales_item</strong>对象相加，两个对象必须表示同一本书。加法结果是一个新的<strong>Sales_item</strong>对象，其ISBN与两个运算对象相同，而其总销售额和售出册数则是两个运算对象的对应值之和。</li><li>使用复合赋值运算符讲一个<strong>Sales_item</strong>对象加到另一个对象上。</li></ul><hr><blockquote><p>重要概念：类定义了行为<br>    当你度这些程序时，类<strong>Sales_item</strong>的作者定义了类对象可以执行的所有动作。即，<strong>Sales_item</strong>类定义了创建一个<strong>Sales_item</strong>对象时会发生什么事情。以及对<strong>Sales_item</strong>对象进行赋值、加法或输入输出运算时会发生什么事情。<br>    一般而言，类的作者决定了类类型对象上可以使用的所有操作。</p><hr></blockquote><p>读写<strong>Sales_item</strong><br>    既然即应知道可以对<strong>Sales_item</strong>对象执行哪些操作，，我们现在就可以便携使用类的程序了。<br>    例如，下面的程序从标准输入读入数据，存入一个<strong>Sales_item</strong>对象中，然后将<strong>Sales_item</strong>的内容写回到标准输出。<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"Sales_item.hpp"</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</div><div class="line">    Sales_item book;</div><div class="line">    </div><div class="line">    <span class="comment">// 读入ISBN号、售出的册数以及销售价格。</span></div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cin</span> &gt;&gt; book;</div><div class="line">    </div><div class="line">    <span class="comment">// 写入ISBN号、售出的册数、总销售额和平均价格。</span></div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; book &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><p>新的include形式：</p><ul><li>来自标准库的头文件 用 ( &lt;&gt; )包围头文件名。</li><li>来自不属于标准库的头文件，用 ( “” )包围。</li></ul><p><strong>Sales_item</strong> 对象的加法<br>下面是一个对象相加的例子。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"addItems.hpp"</span></span></div><div class="line"></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"Sales_item.hpp"</span></span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</div><div class="line">    Sales_item item1, item2;</div><div class="line">    </div><div class="line">    <span class="comment">// 读取一对交易记录</span></div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cin</span> &gt;&gt; item1 &gt;&gt; item2;</div><div class="line">    </div><div class="line">    <span class="comment">//打印和</span></div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; item1 + item2 &lt;&lt; <span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line"></div><div class="line">    <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">    </div><div class="line">&#125;</div></pre></td></tr></table></figure><h3 id="初识成员函数"><a href="#初识成员函数" class="headerlink" title="初识成员函数"></a>初识成员函数</h3><p>将两个<strong>Sales_item</strong>对象相加的程序首先应该价差两个对象是否具有相同的ISBN。<br>方法如下：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"CheckSame.hpp"</span></span></div><div class="line"></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></div><div class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">"Sales_item.hpp"</span></span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span>&#123;</div><div class="line">    Sales_item item1, item2;</div><div class="line">    </div><div class="line">    <span class="comment">// 读取一对交易记录</span></div><div class="line">    <span class="built_in">std</span>::<span class="built_in">cin</span> &gt;&gt; item1 &gt;&gt; item2;</div><div class="line">    </div><div class="line">    <span class="comment">//首先检查item1和item2是否表示相同的书</span></div><div class="line">    <span class="keyword">if</span> (item1.isbn() == item2.isbn()) &#123;</div><div class="line">        <span class="built_in">std</span>::<span class="built_in">cout</span> &lt;&lt; item1 + item2 &lt;&lt;<span class="built_in">std</span>::<span class="built_in">endl</span>;</div><div class="line">    &#125; <span class="keyword">else</span> &#123;</div><div class="line">        <span class="built_in">std</span>::<span class="built_in">cerr</span> &lt;&lt; <span class="string">"Data must refer to same ISBN"</span></div><div class="line">        <span class="keyword">return</span> <span class="number">-1</span>;</div><div class="line">    &#125;</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> <span class="number">0</span>;</div><div class="line">    </div><div class="line">&#125;</div></pre></td></tr></table></figure></p><p>这个if语句的检测条件<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">item1.isbn() == item2.isbn()</div></pre></td></tr></table></figure></p><p>调用名为isbn的<strong>成员函数</strong>。成员函数式定义为类的一部分函数，有时也被称为<strong>方法(method)</strong>。<br>我们通常使用 <strong>点运算符(.)</strong>来调用方法。通常，此方法必须是当前类类型的。<br>当我们访问一个成员函数时，通常我们是想调用该函数，我们使用调用运算符( () )来调用一个函数，调用运算符是一顿圆括号，里面放置<strong>参数列表</strong>(可能为空)。<br>因为我们现在的成员函数 <strong>isbn</strong>并不接受参数，因此：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">item1.isbn()</div></pre></td></tr></table></figure></p><p>调用名为 item1 的对象的成员函数 isbn，此函数返回 item1 中保存的 ISBN书号。</p><p>自此下面的就不去写了， 感觉本书对此处写的像是磕磕绊绊，一些细节性的东西没有去发现， 可能不适合初学者读吧。<br>初学者只想知道为什么运行不起来，不会去关心这些跑不起来的东西竟然还要写例子。</p><h1 id="第二章-变量和基本类型"><a href="#第二章-变量和基本类型" class="headerlink" title="第二章 变量和基本类型"></a>第二章 变量和基本类型</h1><pre><code>数据类型是程序设计的基础，它告诉我们数据的意义以及我们能在数据上执行的操作数据类型决定了程序中数据和操作的意义。如下所示的语句是一个简单示例：<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">i = i + j;</div></pre></td></tr></table></figure>其含义依赖于 i 和 j 的数据类型。 如果i j 是整形数，那么这条语句执行的就是最普通的加法运算。</code></pre><h2 id="基本内置类型"><a href="#基本内置类型" class="headerlink" title="基本内置类型"></a>基本内置类型</h2><p>C++定义了一套包括 <strong>算数尅性</strong> 和 <strong>空类型（void）</strong> 在内的基本数据类型。<br>其中算术类型包含了 字符、整形数、布尔值、和浮点数。空类型不对应具体的值，仅用于一些特殊的场合。<br>例如最常见的是，如果函数不返回任何值的时候使用空类型作为返回类型。</p><h3 id="算术类型"><a href="#算术类型" class="headerlink" title="算术类型"></a>算术类型</h3><p>算术类型分为两类： <strong>整形（包括字符和布尔类型在内）</strong>和浮点型。<br>算数类型的尺寸（也就是该类型数据所占的比特数）在不同机器上有所差别，所表示的范围也不一样。</p><p>布尔类型的取值是 真（true）/假（false）。</p><hr><p>带符号类型和无符号类型<br>    除去布尔型和扩展的字符型之外，其他整形可以划分为<strong>带符号的</strong>和<strong>无符号的</strong>两种。带符号类型可表示正数、负数或0，无符号的类型则仅能表示大禹等于0的值。<br>    类型int、short、long、和long long 都是带符号的，通过在其前面加 unsigened就可以得到无符号类型。<br>    Example：<br>    <figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">unsigened <span class="keyword">int</span></div></pre></td></tr></table></figure></p><hr><p>与其他整形不同，字符型被分为了三种： char、sigend char 和 unsigned char。<br>尽管字符型有三种，但表现形式却只有两种，带符号的和无符号的。具体是哪种由编译器决定。</p><hr><p>建议：如何选择类型<br>    和C语言一样，C++的设计准则之一也是尽可能的接近硬件。C++的算数类型必须满足各种硬件特质。</p><pre><code>- 当明确知道数值不可能为负时，选用无符号类型。- 使用int执行整数运算。- 执行浮点数运算选用double。</code></pre><hr><h3 id="类型转换"><a href="#类型转换" class="headerlink" title="类型转换"></a>类型转换</h3><p>对象的类型定义了对象能包含的数据和能参与的运算，其中一种运算被大多数类型支持，就是讲对象从一种给定的类型<strong>转换</strong>为另一种相关类型。<br>当我们像下面这样发吧一种算术类型的值付给另外一种类型时：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">bool</span> b = <span class="number">42</span>;            <span class="comment">//bw为真</span></div><div class="line"><span class="keyword">int</span> i = b;              <span class="comment">//i的值为1</span></div><div class="line">i = <span class="number">3.14</span>;               <span class="comment">//i的值为3</span></div><div class="line"><span class="keyword">double</span> pi = i;          <span class="comment">//pi的值为3.0</span></div><div class="line">unsigend <span class="keyword">char</span> c = <span class="number">-1</span>;   <span class="comment">//假设char占8bytes c的值为255</span></div><div class="line">sigend <span class="keyword">char</span> c2 = <span class="number">256</span>;   <span class="comment">//假设char占8bytes c2的值是未定义的。</span></div></pre></td></tr></table></figure></p><p>类型所能表示的值的范围决定了转换的过程。</p><ul><li>当我们把一个非布尔类型的算数值赋给布尔类型时，初始值为0则结果为false，否则为true。</li><li>当我们把一个布尔值赋给非布尔类型时，初始值为false则结果为0，否则为1.</li><li>当我们把一个浮点数赋给整数类型时，进行了近似处理。结果值将仅保留浮点数中小数点之前的部分。</li><li>当我们把一个整数值赋给浮点类型时，小数部分记为0.如果该整数所占的空间超过了浮点类型的容量，精度有可能损失。</li><li>当我们赋给带符号类型一个超出它表示范围的值时，结果是未定义的，此时，程序有可能继续工作，可能崩溃，也可能生成垃圾数据。</li><li>当我们赋给无符号类型一个超出它表示范围的值时，结果是初始值对无符号类型表示树枝总数取模后的余数。</li></ul><hr><pre><code>建议：避免无法预知和依赖于实现环境的行为。    无法预知的行为源于编译器无需检测的错误。即使代码编译通过了，如果程序执行了一条未定义的表达式，仍有可能产生错误。    不幸的是，在某些情况或某些编译器下，含有无法预知行为的程序也能正确执行。但是我们却无法保证同样一个程序在别的编译器下能正常工作。甚至已经编译通过的代码再次执行也可能会出错。    程序也应尽量避免依赖于实现环境的行为。</code></pre><hr><h3 id="字面值常亮"><a href="#字面值常亮" class="headerlink" title="字面值常亮"></a>字面值常亮</h3><p>一个形如42的值被称作<strong>字面值常量</strong>，这样的值一望而知。<br>每个字面值常量都对应一种数据类型，字面值常来你的形式和值决定了他的数据类型。</p><h4 id="整型和浮点型字面值"><a href="#整型和浮点型字面值" class="headerlink" title="整型和浮点型字面值"></a>整型和浮点型字面值</h4><pre><code>我们可以将整型字面值写作十进制数、八进制数或十六进制数的形式。以0开头的整数代表八进制数，以0x或者0X开头的代表十六进制。</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;做点什么吧
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="C++" scheme="http://gmle.github.io/categories/C/"/>
    
    
      <category term="C++" scheme="http://gmle.github.io/tags/C/"/>
    
      <category term="C++ Primer" scheme="http://gmle.github.io/tags/C-Primer/"/>
    
  </entry>
  
  <entry>
    <title>对C中堆内存的理解</title>
    <link href="http://gmle.github.io/2017/10/24/%E5%AF%B9%E5%A0%86%E7%9A%84%E5%86%85%E5%AD%98%E5%88%86%E9%85%8D%E7%9A%84%E7%90%86%E8%A7%A3/"/>
    <id>http://gmle.github.io/2017/10/24/对堆的内存分配的理解/</id>
    <published>2017-10-24T05:59:18.412Z</published>
    <updated>2017-11-03T09:35:17.741Z</updated>
    
    <content type="html"><![CDATA[<pre><code>初学者对于堆栈的认识，欢迎吐槽</code></pre><a id="more"></a><h2 id="C-中内存划分"><a href="#C-中内存划分" class="headerlink" title="C++中内存划分"></a>C++中内存划分</h2><p>c++划分为五个区：</p><ul><li>堆<ul><li>堆，就是那些由new分配的内存块，他们的释放编译器不去管，由我们的应用程序去控制，一般一个new就要对应一个delete.如果程序员没有释放掉，那么在程序结束后，操作系统会自动回收。</li></ul></li><li>栈<ul><li>栈，就是那些由编译器在需要的时候分配，在不需要的时候自动清楚的变量的存储区。里面的变量通常是局部变量、函数参数等。</li></ul></li><li>自由存储区<ul><li>就是那些由malloc等分配的内存块，他和堆是十分相似的，不过它是用free来结束自己的生命的。</li></ul></li><li>全局、静态存储区<ul><li>全局变量和静态变量被分配到同一块内存中，在以前的C语言中，全局变量又分为初始化的和未初始化的，在C++里面没有这个区分了，他们共同占用同一块内存区。</li></ul></li><li>常亮存储区<ul><li>这是一块比较特殊的存储区，他们里面存放的是常量，不允许修改(当然，你要通过非正当手段也可以修改)</li></ul></li></ul><h2 id="C-内存区域中堆和栈的区别："><a href="#C-内存区域中堆和栈的区别：" class="headerlink" title="C++内存区域中堆和栈的区别："></a>C++内存区域中堆和栈的区别：</h2><h3 id="管理方式不同："><a href="#管理方式不同：" class="headerlink" title="管理方式不同："></a>管理方式不同：</h3><ul><li>栈是由编译器自动管理，无需我们手工控制。</li><li>堆的释放由程序员完成，容易产生内存泄漏。</li></ul><h3 id="空间大小不同："><a href="#空间大小不同：" class="headerlink" title="空间大小不同："></a>空间大小不同：</h3><ul><li>堆内存很大。</li><li>栈内存可修改，但默认好像非常小。</li></ul><h3 id="内存碎片："><a href="#内存碎片：" class="headerlink" title="内存碎片："></a>内存碎片：</h3><ul><li>对于堆来讲，频繁的new/delete势必会造成内存空间的不连续，从而造成大量的碎片，使程序效率降低。</li><li>对于栈来讲，则不会存在这个问题。</li></ul><h3 id="生长方向不同："><a href="#生长方向不同：" class="headerlink" title="生长方向不同："></a>生长方向不同：</h3><ul><li>对于堆来讲，生长方向是向上的，也就是向着内存地址增加的方向；</li><li>对于栈来讲，它的生长方式是向下的，是向着内存地址减小的方向增长。<ul><li>加深理解的话：<ul><li>在函数体中定义的变量通常是在栈上，定义一个变量，内存就少一点。就像一杯水喝一口</li><li>堆用malloc， calloc， realloc等分配内存的函数分配得到的就是在堆上<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">int</span> a = <span class="number">0</span>; <span class="comment">//全局初始化区  </span></div><div class="line"><span class="keyword">char</span> *p1; <span class="comment">//全局未初始化区  </span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">main</span><span class="params">()</span> </span>&#123;  </div><div class="line">    <span class="keyword">int</span> b; <span class="comment">//栈  </span></div><div class="line">    <span class="keyword">char</span> s[] = <span class="string">"abc"</span>;          <span class="comment">//栈  </span></div><div class="line">    <span class="keyword">char</span> *p2;                  <span class="comment">//栈  </span></div><div class="line">    <span class="keyword">char</span> *p3 = <span class="string">"123456"</span>;       <span class="comment">//123456&#123;post.content&#125;在常量区，p3在栈上  </span></div><div class="line">    <span class="keyword">static</span> <span class="keyword">int</span> c = <span class="number">0</span>;          <span class="comment">//全局(静态)初始化区  </span></div><div class="line">    p1 = (<span class="keyword">char</span> *)<span class="built_in">malloc</span>(<span class="number">10</span>);   <span class="comment">//分配得来得10字节的区域在堆区  </span></div><div class="line">    p2 = (<span class="keyword">char</span> *)<span class="built_in">malloc</span>(<span class="number">20</span>);   <span class="comment">//分配得来得20字节的区域在堆区  </span></div><div class="line">    <span class="built_in">strcpy</span>(p1, <span class="string">"123456"</span>);      <span class="comment">//123456&#123;post.content&#125;放在常量区，编译器可能会将它与p3所指向的"123456"优化成一块  </span></div><div class="line">&#125;</div></pre></td></tr></table></figure></li></ul></li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;初学者对于堆栈的认识，欢迎吐槽
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="C++" scheme="http://gmle.github.io/categories/C/"/>
    
    
      <category term="C++" scheme="http://gmle.github.io/tags/C/"/>
    
      <category term="内存管理" scheme="http://gmle.github.io/tags/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>Spark-HA的worker问题</title>
    <link href="http://gmle.github.io/2017/10/10/Spark-HA%E7%9A%84worker%E9%97%AE%E9%A2%98/"/>
    <id>http://gmle.github.io/2017/10/10/Spark-HA的worker问题/</id>
    <published>2017-10-10T03:36:26.000Z</published>
    <updated>2017-11-06T08:39:00.000Z</updated>
    
    <content type="html"><![CDATA[<p>关于 HA 中 Spark worker节点连接Master的问题</p><a id="more"></a><h2 id="问题：Spark-Woker-不去连接ALIVE-Master"><a href="#问题：Spark-Woker-不去连接ALIVE-Master" class="headerlink" title="问题：Spark Woker 不去连接ALIVE Master"></a>问题：Spark Woker 不去连接ALIVE Master</h2><p>机器：</p><ul><li>192.168.1.128 Master</li><li>192.168.1.129 Master Worker</li><li><p>192.168.1.130 Worker</p><p>启动时两个Master的状态不可控，不知道哪个是ALIVE的Master，worker节点在连接Master的时候，会判断当前Master的状态是否为ALIVE，如果为StandBy，则不继续链接，然后去寻找ALIVE，直到找到ALIVE节点的MASTER。</p><p>现在的问题是 Worker在找到StandBy节点后，并没有去寻找新的Master，导致了worker注册不到集群上，自动关闭。</p><p>原因待定。</p><p>根据一些帖子发现，如果配置了Spark on yarn ，则 Spark HA 基本没有任何作用。</p></li></ul><!-- more --><p>错误日志</p><ul><li>Terminal<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div></pre></td><td class="code"><pre><div class="line">Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties</div><div class="line">17/10/09 13:05:08 INFO Worker: Registered signal handlers for [TERM, HUP, INT]</div><div class="line">17/10/09 13:05:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable</div><div class="line">17/10/09 13:05:09 INFO SecurityManager: Changing view acls to: root</div><div class="line">17/10/09 13:05:09 INFO SecurityManager: Changing modify acls to: root</div><div class="line">17/10/09 13:05:09 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root); users with modify permissions: Set(root)</div><div class="line">17/10/09 13:05:10 INFO Utils: Successfully started service 'sparkWorker' on port 39766.</div><div class="line">17/10/09 13:05:10 INFO Worker: Starting Spark worker 192.168.10.129:39766 with 4 cores, 4.0 GB RAM</div><div class="line">17/10/09 13:05:10 INFO Worker: Running Spark version 1.6.0</div><div class="line">17/10/09 13:05:10 INFO Worker: Spark home: /opt/dkh/spark-1.6.0-bin-hadoop2.6</div><div class="line">17/10/09 13:05:11 INFO Utils: Successfully started service 'WorkerUI' on port 8081.</div><div class="line">17/10/09 13:05:11 INFO WorkerWebUI: Started WorkerWebUI at http://192.168.10.129:8081</div><div class="line">17/10/09 13:05:11 INFO Worker: Connecting to master dkm:7077...</div><div class="line">17/10/09 13:05:11 WARN Worker: Failed to connect to master dkm:7077</div><div class="line">java.io.IOException: Failed to connect to dkm/192.168.10.128:7077</div><div class="line">at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:216)</div><div class="line">at org.apache.spark.network.client.TransportClientFactory.createClient(TransportClientFactory.java:167)</div><div class="line">at org.apache.spark.rpc.netty.NettyRpcEnv.createClient(NettyRpcEnv.scala:200)</div><div class="line">at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:187)</div><div class="line">at org.apache.spark.rpc.netty.Outbox$$anon$1.call(Outbox.scala:183)</div><div class="line">at java.util.concurrent.FutureTask.run(FutureTask.java:262)</div><div class="line">at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1145)</div><div class="line">at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:615)</div><div class="line">at java.lang.Thread.run(Thread.java:745)</div><div class="line">Caused by: java.net.ConnectException: 拒绝连接: dkm/192.168.10.128:7077</div><div class="line">at sun.nio.ch.SocketChannelImpl.checkConnect(Native Method)</div><div class="line">at sun.nio.ch.SocketChannelImpl.finishConnect(SocketChannelImpl.java:739)</div><div class="line">at io.netty.channel.socket.nio.NioSocketChannel.doFinishConnect(NioSocketChannel.java:224)</div><div class="line">at io.netty.channel.nio.AbstractNioChannel$AbstractNioUnsafe.finishConnect(AbstractNioChannel.java:289)</div><div class="line">at io.netty.channel.nio.NioEventLoop.processSelectedKey(NioEventLoop.java:528)</div><div class="line">at io.netty.channel.nio.NioEventLoop.processSelectedKeysOptimized(NioEventLoop.java:468)</div><div class="line">at io.netty.channel.nio.NioEventLoop.processSelectedKeys(NioEventLoop.java:382)</div><div class="line">at io.netty.channel.nio.NioEventLoop.run(NioEventLoop.java:354)</div><div class="line">at io.netty.util.concurrent.SingleThreadEventExecutor$2.run(SingleThreadEventExecutor.java:111)</div><div class="line">... 1 more</div><div class="line">17/10/09 13:05:24 INFO Worker: Retrying connection to master (attempt # 1)</div><div class="line">17/10/09 13:05:24 INFO Worker: Connecting to master dkm:7077...</div><div class="line">17/10/09 13:05:37 INFO Worker: Retrying connection to master (attempt # 2)</div><div class="line">17/10/09 13:05:37 INFO Worker: Connecting to master dkm:7077...</div><div class="line">17/10/09 13:05:50 INFO Worker: Retrying connection to master (attempt # 3)</div><div class="line">17/10/09 13:05:50 INFO Worker: Connecting to master dkm:7077...</div><div class="line">17/10/09 13:06:03 INFO Worker: Retrying connection to master (attempt # 4)</div><div class="line">17/10/09 13:06:03 INFO Worker: Connecting to master dkm:7077...</div><div class="line">17/10/09 13:06:16 INFO Worker: Retrying connection to master (attempt # 5)</div><div class="line">17/10/09 13:06:16 INFO Worker: Connecting to master dkm:7077...</div><div class="line">17/10/09 13:06:29 INFO Worker: Retrying connection to master (attempt # 6)</div><div class="line">17/10/09 13:06:29 INFO Worker: Connecting to master dkm:7077...</div><div class="line">17/10/09 13:07:47 INFO Worker: Retrying connection to master (attempt # 7)</div><div class="line">17/10/09 13:07:47 INFO Worker: Connecting to master dkm:7077...</div><div class="line">17/10/09 13:09:05 INFO Worker: Retrying connection to master (attempt # 8)</div><div class="line">17/10/09 13:09:05 INFO Worker: Connecting to master dkm:7077...</div><div class="line">17/10/09 13:10:23 INFO Worker: Retrying connection to master (attempt # 9)</div><div class="line">17/10/09 13:10:23 INFO Worker: Connecting to master dkm:7077...</div><div class="line">17/10/09 13:11:41 INFO Worker: Retrying connection to master (attempt # 10)</div><div class="line">17/10/09 13:11:41 INFO Worker: Connecting to master dkm:7077...</div><div class="line">17/10/09 13:12:59 INFO Worker: Retrying connection to master (attempt # 11)</div><div class="line">17/10/09 13:12:59 INFO Worker: Connecting to master dkm:7077...</div><div class="line">17/10/09 13:14:17 INFO Worker: Retrying connection to master (attempt # 12)</div><div class="line">17/10/09 13:14:17 INFO Worker: Connecting to master dkm:7077...</div><div class="line">17/10/09 13:15:35 INFO Worker: Retrying connection to master (attempt # 13)</div><div class="line">17/10/09 13:15:35 INFO Worker: Connecting to master dkm:7077...</div><div class="line">17/10/09 13:16:53 INFO Worker: Retrying connection to master (attempt # 14)</div><div class="line">17/10/09 13:16:53 INFO Worker: Connecting to master dkm:7077...</div><div class="line">17/10/09 13:18:11 INFO Worker: Retrying connection to master (attempt # 15)</div><div class="line">17/10/09 13:18:11 INFO Worker: Connecting to master dkm:7077...</div><div class="line">17/10/09 13:19:29 INFO Worker: Retrying connection to master (attempt # 16)</div><div class="line">17/10/09 13:19:29 INFO Worker: Connecting to master dkm:7077...</div><div class="line">17/10/09 13:20:47 ERROR Worker: All masters are unresponsive! Giving up.</div></pre></td></tr></table></figure></li></ul><p>既然如此，那干脆不启动第二个Master，Start-all 后，会发现集群正常，但是没有第二个Master。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;关于 HA 中 Spark worker节点连接Master的问题&lt;/p&gt;
    
    </summary>
    
      <category term="Spark" scheme="http://gmle.github.io/categories/Spark/"/>
    
    
      <category term="Shell" scheme="http://gmle.github.io/tags/Shell/"/>
    
      <category term="Spark" scheme="http://gmle.github.io/tags/Spark/"/>
    
      <category term="Linux" scheme="http://gmle.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>关于Spark环境变量问题</title>
    <link href="http://gmle.github.io/2017/09/13/%E5%85%B3%E4%BA%8ESpark%E7%8E%AF%E5%A2%83%E5%8F%98%E9%87%8F%E9%97%AE%E9%A2%98/"/>
    <id>http://gmle.github.io/2017/09/13/关于Spark环境变量问题/</id>
    <published>2017-09-13T02:07:56.000Z</published>
    <updated>2017-11-06T08:44:11.000Z</updated>
    
    <content type="html"><![CDATA[<p>记录一次因为spark内置环境问题引发的惨案</p><a id="more"></a><h2 id="问题：Spark在spark-env-sh中的环境变量不生效"><a href="#问题：Spark在spark-env-sh中的环境变量不生效" class="headerlink" title="问题：Spark在spark-env.sh中的环境变量不生效"></a>问题：Spark在spark-env.sh中的环境变量不生效</h2><!-- more --><p>错误日志</p><ul><li>Terminal<figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line">[root@ceshi3 sbin]# ./start-slaves.sh </div><div class="line">- /usr/local/spark-1.6.0-bin-hadoop2.6/conf/spark-env.sh: line 9: export: `/usr/local/spark-1.6.0-bin-hadoop2.6/lib/spark-assembly-1.6.0-hadoop2.6.0.jar': not a valid identifier</div><div class="line">- ceshi3: /usr/local/spark-1.6.0-bin-hadoop2.6/conf/spark-env.sh: line 9: export: `/usr/local/spark-1.6.0-bin-hadoop2.6/lib/spark-assembly-1.6.0-hadoop2.6.0.jar': not a valid identifier</div><div class="line">- ceshi3: starting org.apache.spark.deploy.worker.Worker, logging to /usr/local/spark-1.6.0-bin-hadoop2.6/logs/spark-root-org.apache.spark.deploy.worker.Worker-1-ceshi3.out</div><div class="line">- ceshi3: failed to launch org.apache.spark.deploy.worker.Worker:</div><div class="line">- ceshi3:   /usr/local/spark-1.6.0-bin-hadoop2.6/bin/spark-class: line 87: /usr/local/spark-1.6.0-bin-hadoop2.6/bin/java: 没有那个文件或目录</div><div class="line">- ceshi3:   /usr/local/spark-1.6.0-bin-hadoop2.6/bin/spark-class: line 87: exec: /usr/local/spark-1.6.0-bin-hadoop2.6/bin/java: cannot execute: 没有那个文件或目录</div><div class="line">- ceshi3: full log in /usr/local/spark-1.6.0-bin-hadoop2.6/logs/spark-root-org.apache.spark.deploy.worker.Worker-1-ceshi3.out</div></pre></td></tr></table></figure></li></ul><p>发现启动worker的时候会出现错误：<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">- ceshi3:   /usr/local/spark-1.6.0-bin-hadoop2.6/bin/spark-class: line 87: /usr/local/spark-1.6.0-bin-hadoop2.6/bin/java: 没有那个文件或目录</div><div class="line">- ceshi3:   /usr/local/spark-1.6.0-bin-hadoop2.6/bin/spark-class: line 87: exec: /usr/local/spark-1.6.0-bin-hadoop2.6/bin/java: cannot execute: 没有那个文件或目录</div></pre></td></tr></table></figure></p><p>这个bin/java明明是$ JAVA_HOME 的，为什么会变为 $SPARK_HOME 呢</p><p>既然启动报错，而且报的是 $JAVA_HOME，那就要看几个东西:一个是正常的系统变量配置，再一个就是在要启动的服务里是否使用了这个配置变量，再确认下自己的配置是否已经有了。</p><h2 id="查看-spark-关于环境变量的配置文件"><a href="#查看-spark-关于环境变量的配置文件" class="headerlink" title="查看 spark 关于环境变量的配置文件"></a>查看 spark 关于环境变量的配置文件</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line">export SPARK_DAEMON_JAVA_OPTS="-Dspark.deploy.recoveryMode=ZOOKEEPER -Dspark.deploy.zookeeper.url=dk31:2181,dk32:2181,dk34:2181 -Dspark.deploy.zookeeper.dir=/spark"</div><div class="line">export JAVA_HOME=$&#123;JAVA_HOME&#125;</div><div class="line">export HADOOP_HOME=/usr/local/hadoop-2.6.0</div><div class="line">export HADOOP_CONF_DIR=$&#123;HADOOP_HOME&#125;/etc/hadoop</div><div class="line">export SCALA_HOME=/usr/local/scala-2.10.4</div><div class="line">export SPARK_WORKER_MEMORY=4g</div><div class="line">export SPARK_EXECUTOR_MEMORY=2g</div><div class="line">export SPARK_DRIVER_MEMORY=1g</div><div class="line">export SPARK_WORKER_CORES=4</div><div class="line">export SPARK_CLASSPATH=/usr/local/spark-1.6.0-bin-hadoop2.6/lib/mysql-connector-java.jar</div><div class="line">export SPARK_CLASSPATH=$SPARK_CLASSPATH:$CLASSPATH</div></pre></td></tr></table></figure><p>发现 $JAVA_HOME 变量是取的系统变量·，但是系统变量为什么取不到？</p><p>查了下：在脚本中使用export, 只在脚本中有效，退出这个脚本，设置的变量就没有了。<br>由于spark-class使用了 spark-env.sh 在使用的时候 已经取不到该值，所以无效了。<br>但是想不通为什么会变成 $SPARK_HOME 的变量</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;记录一次因为spark内置环境问题引发的惨案&lt;/p&gt;
    
    </summary>
    
      <category term="Spark" scheme="http://gmle.github.io/categories/Spark/"/>
    
    
      <category term="Shell" scheme="http://gmle.github.io/tags/Shell/"/>
    
      <category term="Spark" scheme="http://gmle.github.io/tags/Spark/"/>
    
      <category term="Linux" scheme="http://gmle.github.io/tags/Linux/"/>
    
  </entry>
  
  <entry>
    <title>Maven一键安装 centos平台</title>
    <link href="http://gmle.github.io/2017/09/12/yum%E4%B8%80%E9%94%AE%E5%AE%89%E8%A3%85maven/"/>
    <id>http://gmle.github.io/2017/09/12/yum一键安装maven/</id>
    <published>2017-09-12T02:44:47.000Z</published>
    <updated>2017-09-12T02:48:22.000Z</updated>
    
    <content type="html"><![CDATA[<pre><code>maven一键安装</code></pre><a id="more"></a><h2 id="添加maven的仓库"><a href="#添加maven的仓库" class="headerlink" title="添加maven的仓库"></a>添加maven的仓库</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">wget http://repos.fedorapeople.org/repos/dchen/apache-maven/epel-apache-maven.repo -O /etc/yum.repos.d/epel-apache-maven.repo</div></pre></td></tr></table></figure><h2 id="yum-安装"><a href="#yum-安装" class="headerlink" title="yum 安装"></a>yum 安装</h2><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum -y install apache-maven</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;maven一键安装
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="linux" scheme="http://gmle.github.io/categories/linux/"/>
    
    
      <category term="Centos" scheme="http://gmle.github.io/tags/Centos/"/>
    
      <category term="maven" scheme="http://gmle.github.io/tags/maven/"/>
    
  </entry>
  
  <entry>
    <title>C++标准库</title>
    <link href="http://gmle.github.io/2017/08/04/C++%E6%A0%87%E5%87%86%E5%BA%93/"/>
    <id>http://gmle.github.io/2017/08/04/C++标准库/</id>
    <published>2017-08-04T09:17:18.000Z</published>
    <updated>2017-08-04T09:55:45.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="C-标准库可以分为两个部分："><a href="#C-标准库可以分为两个部分：" class="headerlink" title="C++标准库可以分为两个部分："></a>C++标准库可以分为两个部分：</h2><ul><li>标准函数库：继承自C语言；</li><li>面向对象库：是类及其相关函数的集合；</li></ul><a id="more"></a><h2 id="标准函数库："><a href="#标准函数库：" class="headerlink" title="标准函数库："></a>标准函数库：</h2><h4 id="输入-输出I-O-；"><a href="#输入-输出I-O-；" class="headerlink" title="输入 / 输出I/O ；"></a>输入 / 输出I/O ；</h4><ul><li>字符串和字符处理；</li><li>数学；</li><li>时间、日期和本地化；</li><li>动态分配；</li><li>其他；</li><li>宽字符函数；<h2 id="面向对象类："><a href="#面向对象类：" class="headerlink" title="面向对象类："></a>面向对象类：</h2></li><li>标准的C++ I/O类；</li><li>String类；</li><li>数值类；</li><li>STL容器类；</li><li>STL算法；</li><li>STL函数对象；</li><li>STL迭代器；</li><li>STL分配器；</li><li>本地化库；</li><li>异常处理类；</li><li>杂项支持库；</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;C-标准库可以分为两个部分：&quot;&gt;&lt;a href=&quot;#C-标准库可以分为两个部分：&quot; class=&quot;headerlink&quot; title=&quot;C++标准库可以分为两个部分：&quot;&gt;&lt;/a&gt;C++标准库可以分为两个部分：&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;标准函数库：继承自C语言；&lt;/li&gt;
&lt;li&gt;面向对象库：是类及其相关函数的集合；&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="C++" scheme="http://gmle.github.io/categories/C/"/>
    
    
      <category term="C++" scheme="http://gmle.github.io/tags/C/"/>
    
  </entry>
  
  <entry>
    <title>Bash/Shell调用MySQL并忽略警告</title>
    <link href="http://gmle.github.io/2017/06/23/Bash%E8%B0%83%E7%94%A8MySql/"/>
    <id>http://gmle.github.io/2017/06/23/Bash调用MySql/</id>
    <published>2017-06-23T06:09:03.000Z</published>
    <updated>2017-06-25T09:26:19.000Z</updated>
    
    <content type="html"><![CDATA[<pre><code>Shell对MySQL的调用与脚本中如何写</code></pre><h2 id="Shell脚本如何搞定-MySQL的增删改查"><a href="#Shell脚本如何搞定-MySQL的增删改查" class="headerlink" title="Shell脚本如何搞定 MySQL的增删改查"></a>Shell脚本如何搞定 MySQL的增删改查</h2><a id="more"></a><p>用Shell对mysql操作非常的简单<br>我们利用 mysql 命令去操作数据库里面的所有东西。</p><ul><li>shell脚本<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="comment"># 一坨一坨的运行：</span></div><div class="line">mysql -uroot -p123456 -e <span class="string">"</span></div><div class="line"><span class="string">select * from tmp_test where tmp_name = 'a';</span></div><div class="line"><span class="string">select * from tmp_test where tmp_name = 'b';</span></div><div class="line"><span class="string">select * from tmp_test where tmp_id = 1;</span></div><div class="line"><span class="string">select tmp_name from tmp_test where tmp_id = 2;</span></div><div class="line"><span class="string">quit</span></div><div class="line"><span class="string">"</span></div><div class="line"></div><div class="line"><span class="comment"># 赋值：</span></div><div class="line">id=$(mysql -uroot -p123456 -e <span class="string">"SELECT tmp_id from tmp_test WHERE tmp_name = 'a';"</span>)</div><div class="line"><span class="comment"># 会发现还有字段名字，加参数去掉字段名，只保留我们要查询的：</span></div><div class="line">id=$(mysql -uroot -p123456 -Bse <span class="string">"SELECT tmp_id from tmp_test WHERE tmp_name = 'a';"</span>)</div></pre></td></tr></table></figure></li></ul><p>过后我们会发现每次查询之后会出现警告，每次都出：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">mysql: [Warning] Using a password on the <span class="built_in">command</span> line interface can be insecure.</div></pre></td></tr></table></figure></p><h2 id="MySQL-版本-5-6-的安全策略"><a href="#MySQL-版本-5-6-的安全策略" class="headerlink" title="MySQL 版本 5.6+ 的安全策略"></a>MySQL 版本 5.6+ 的安全策略</h2><p>MySQL5.6版本向上有一个密码安全问题，即在命令行输入密码会出现警告：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mysql -uroot -proot  </div><div class="line">mysql: [Warning] Using a password on the <span class="built_in">command</span> line interface can be insecure.</div></pre></td></tr></table></figure><p>读取配置文件的参数也不可以，这样我们 需要指定一个mysql的配置文件作为mysql的配置输入进去：</p><p>cnf配置文件<br>my.cnf<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#!/bin/bash</span></div><div class="line">[mysql]</div><div class="line">password=root</div></pre></td></tr></table></figure></p><p>然后再在脚本中调用：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">#!/bin/bash</span></div><div class="line"><span class="comment"># 继续赋值，这样就不会出现警告信息：</span></div><div class="line">id=$(mysql --defaults-file=./my.cnf -uroot -Bse <span class="string">"SELECT tmp_id from tmp_test WHERE tmp_name = 'a';"</span>)</div></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;Shell对MySQL的调用与脚本中如何写
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;Shell脚本如何搞定-MySQL的增删改查&quot;&gt;&lt;a href=&quot;#Shell脚本如何搞定-MySQL的增删改查&quot; class=&quot;headerlink&quot; title=&quot;Shell脚本如何搞定 MySQL的增删改查&quot;&gt;&lt;/a&gt;Shell脚本如何搞定 MySQL的增删改查&lt;/h2&gt;
    
    </summary>
    
      <category term="Shell" scheme="http://gmle.github.io/categories/Shell/"/>
    
    
      <category term="Shell" scheme="http://gmle.github.io/tags/Shell/"/>
    
      <category term="Bash" scheme="http://gmle.github.io/tags/Bash/"/>
    
      <category term="MySQL" scheme="http://gmle.github.io/tags/MySQL/"/>
    
  </entry>
  
  <entry>
    <title>在Centos6.5下升级python至3.6.0</title>
    <link href="http://gmle.github.io/2017/05/11/centos6.5%E4%B8%8Bpython2.6.6%E5%8D%87%E7%BA%A7%E8%87%B33.6/"/>
    <id>http://gmle.github.io/2017/05/11/centos6.5下python2.6.6升级至3.6/</id>
    <published>2017-05-11T02:16:11.000Z</published>
    <updated>2017-05-11T07:57:48.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="此次升级保留旧版本的环境。"><a href="#此次升级保留旧版本的环境。" class="headerlink" title="此次升级保留旧版本的环境。"></a>此次升级保留旧版本的环境。</h2><a id="more"></a><h2 id="配置系统环境"><a href="#配置系统环境" class="headerlink" title="配置系统环境"></a>配置系统环境</h2><h3 id="安装开发工具"><a href="#安装开发工具" class="headerlink" title="安装开发工具"></a>安装开发工具</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum groupinstall -y developement</div></pre></td></tr></table></figure><h3 id="安装python3解码支持包"><a href="#安装python3解码支持包" class="headerlink" title="安装python3解码支持包"></a>安装python3解码支持包</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum install -y zlib-devel openssl-devel sqlite-devel bzip2-devel</div></pre></td></tr></table></figure><h2 id="准备更新版本"><a href="#准备更新版本" class="headerlink" title="准备更新版本"></a>准备更新版本</h2><h3 id="验证原有的python版本"><a href="#验证原有的python版本" class="headerlink" title="验证原有的python版本"></a>验证原有的python版本</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python -V</div></pre></td></tr></table></figure><p>python 2.6.6</p><h3 id="下载python3-6-0包"><a href="#下载python3-6-0包" class="headerlink" title="下载python3.6.0包"></a>下载python3.6.0包</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">wget http://www.python.org/ftp/python/3.6.0/Python-3.6.0.tar.xz</div></pre></td></tr></table></figure><h3 id="解压编译python安装包"><a href="#解压编译python安装包" class="headerlink" title="解压编译python安装包"></a>解压编译python安装包</h3><h4 id="解压"><a href="#解压" class="headerlink" title="解压"></a>解压</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">xz -d Python-3.6.0.tar.xz</div><div class="line">tar -xvf Python-3.6.0.tar</div></pre></td></tr></table></figure><h4 id="编译"><a href="#编译" class="headerlink" title="编译"></a>编译</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">cd Python-3.6.0</div><div class="line"><span class="meta">#</span><span class="bash"> 配置安装路径</span></div><div class="line">./configure --prefix=/usr/local</div></pre></td></tr></table></figure><ul><li><p>如果出现编译错误可能是因为gcc gcc-c++版本太低或者未安装，使用代码</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">yum -y install gcc gcc-c++</div></pre></td></tr></table></figure></li><li><p>进行安装，然后重新编译./configure</p><h3 id="执行安装"><a href="#执行安装" class="headerlink" title="执行安装"></a>执行安装</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">make &amp;&amp; make altinstall</div></pre></td></tr></table></figure></li></ul><h3 id="建立软连接-就是快捷方式"><a href="#建立软连接-就是快捷方式" class="headerlink" title="建立软连接(就是快捷方式)"></a>建立软连接(就是快捷方式)</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">mv /usr/bin/python /usr/bin/python2.6.6    ##你的python版本可能不同</div><div class="line">ln -s /usr/local/bin/python3.6 /usr/bin/python</div></pre></td></tr></table></figure><ul><li><p>重新验证python版本，</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">python -V</div></pre></td></tr></table></figure></li><li><p>python3.6.0</p></li></ul><h3 id="yum指令会报错，将其重新指向旧版本的python"><a href="#yum指令会报错，将其重新指向旧版本的python" class="headerlink" title="yum指令会报错，将其重新指向旧版本的python"></a>yum指令会报错，将其重新指向旧版本的python</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">vi /usr/bin/yum</div></pre></td></tr></table></figure><ul><li>将文件的头部#！/usr/bin/python改为#！/usr/bin/python2.6.6</li></ul><h3 id="安装新pip"><a href="#安装新pip" class="headerlink" title="安装新pip"></a>安装新pip</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="meta">$</span><span class="bash"> wget https://pypi.python.org/packages/<span class="built_in">source</span>/p/pip/pip-1.3.1.tar.gz --no-check-certificate</span></div></pre></td></tr></table></figure><h4 id="解压安装pip"><a href="#解压安装pip" class="headerlink" title="解压安装pip"></a>解压安装pip</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">chmod +x pip-1.3.1.tar.gz</div><div class="line">tar xzvf pip-1.3.1.tar.gz</div><div class="line">cd pip-1.3.1</div><div class="line">python setup.py install</div></pre></td></tr></table></figure><h4 id="查看pip安装"><a href="#查看pip安装" class="headerlink" title="查看pip安装"></a>查看pip安装</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">pip -V</div></pre></td></tr></table></figure><ul><li>pip 1.3.1 from /usr/local/lib/python3.6/site-packages/pip-1.3.1-py3.6.egg (python 3.6)</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;此次升级保留旧版本的环境。&quot;&gt;&lt;a href=&quot;#此次升级保留旧版本的环境。&quot; class=&quot;headerlink&quot; title=&quot;此次升级保留旧版本的环境。&quot;&gt;&lt;/a&gt;此次升级保留旧版本的环境。&lt;/h2&gt;
    
    </summary>
    
      <category term="Centos" scheme="http://gmle.github.io/categories/Centos/"/>
    
    
      <category term="Centos" scheme="http://gmle.github.io/tags/Centos/"/>
    
      <category term="Python" scheme="http://gmle.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>MacOS下配置Hadoop和Spark</title>
    <link href="http://gmle.github.io/2017/05/02/MacOS%E5%AE%89%E8%A3%85Hadoop&amp;Spark/"/>
    <id>http://gmle.github.io/2017/05/02/MacOS安装Hadoop&amp;Spark/</id>
    <published>2017-05-02T07:49:44.000Z</published>
    <updated>2017-05-03T06:37:38.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="首先，准备MacOS环境"><a href="#首先，准备MacOS环境" class="headerlink" title="首先，准备MacOS环境"></a>首先，准备MacOS环境</h2><pre><code>略过Java、Scala、Python的环境安装，从Hadoop和Spark说起</code></pre><a id="more"></a><h2 id="安装Hadoop"><a href="#安装Hadoop" class="headerlink" title="安装Hadoop"></a>安装Hadoop</h2><p>安装Hadoop，最简单的安装方式：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">brew install hadoop</div></pre></td></tr></table></figure></p><h4 id="找到安装目录"><a href="#找到安装目录" class="headerlink" title="找到安装目录"></a>找到安装目录</h4><pre><code>安装完成后，找到Hadoop配置文件目录：</code></pre><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/Cellar/hadoop/2.7.3/libexec/etc/hadoop</div></pre></td></tr></table></figure><h4 id="修改core-site-xml"><a href="#修改core-site-xml" class="headerlink" title="修改core-site.xml"></a>修改core-site.xml</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span>  </div><div class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </div><div class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>hadoop.tmp.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </div><div class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/Cellar/hadoop/2.7.3/libexec/tmp<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </div><div class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </div><div class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </div><div class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.defaultFS<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </div><div class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>hdfs://localhost:8020<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </div><div class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </div><div class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></div></pre></td></tr></table></figure><h4 id="修改hdfs-site-xml"><a href="#修改hdfs-site-xml" class="headerlink" title="修改hdfs-site.xml"></a>修改hdfs-site.xml</h4><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">configuration</span>&gt;</span>  </div><div class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </div><div class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.replication<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </div><div class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>1<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </div><div class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </div><div class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </div><div class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.name.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </div><div class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/Cellar/hadoop/2.7.3/libexec/tmp/dfs/name<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </div><div class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </div><div class="line">        <span class="tag">&lt;<span class="name">property</span>&gt;</span>  </div><div class="line">                <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.data.dir<span class="tag">&lt;/<span class="name">name</span>&gt;</span>  </div><div class="line">                <span class="tag">&lt;<span class="name">value</span>&gt;</span>file:/usr/local/Cellar/hadoop/2.7.3/libexec/tmp/dfs/data<span class="tag">&lt;/<span class="name">value</span>&gt;</span>  </div><div class="line">        <span class="tag">&lt;/<span class="name">property</span>&gt;</span>  </div><div class="line"><span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></div></pre></td></tr></table></figure><h4 id="添加环境变量"><a href="#添加环境变量" class="headerlink" title="添加环境变量"></a>添加环境变量</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="comment">#Hadoop environment configs  </span></div><div class="line"><span class="built_in">export</span> HADOOP_HOME=/usr/<span class="built_in">local</span>/Cellar/hadoop/2.7.3/libexec  </div><div class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$&#123;HADOOP_HOME&#125;</span>/bin</div></pre></td></tr></table></figure><h4 id="格式化HDFS"><a href="#格式化HDFS" class="headerlink" title="格式化HDFS"></a>格式化HDFS</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/Cellar/hadoop/2.7.3/bin  </div><div class="line">./hdfs namenode -format</div></pre></td></tr></table></figure><h4 id="启动Hadoop"><a href="#启动Hadoop" class="headerlink" title="启动Hadoop"></a>启动Hadoop</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/Cellar/hadoop/2.7.3/sbin  </div><div class="line">./start-all.sh</div></pre></td></tr></table></figure><p>在终端输入 jps 查看java进程<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">1206 DataNode  </div><div class="line">1114 NameNode  </div><div class="line">1323 SecondaryNameNode</div></pre></td></tr></table></figure></p><h2 id="安装Spark"><a href="#安装Spark" class="headerlink" title="安装Spark"></a>安装Spark</h2><p>Spark的安装也是使用 brew<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">brew install apache-spark</div></pre></td></tr></table></figure></p><h4 id="找到安装目录-1"><a href="#找到安装目录-1" class="headerlink" title="找到安装目录"></a>找到安装目录</h4><p>找到Spark配置文件目录<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">cd</span> /usr/<span class="built_in">local</span>/Cellar/apache-spark/2.1.0/libexec/conf</div></pre></td></tr></table></figure></p><h4 id="修改spark-env-sh"><a href="#修改spark-env-sh" class="headerlink" title="修改spark-env.sh"></a>修改spark-env.sh</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line">cp spark-env.sh.template spark-env.sh</div><div class="line">vi spark-env.sh</div><div class="line"><span class="built_in">export</span> SPARK_HOME=/usr/<span class="built_in">local</span>/Cellar/apache-spark/2.1.0/libexec  </div><div class="line"><span class="built_in">export</span> JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_102.jdk/Contents/Home</div></pre></td></tr></table></figure><h4 id="加入环境变量"><a href="#加入环境变量" class="headerlink" title="加入环境变量"></a>加入环境变量</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">export</span> SPARK_HOME=/usr/<span class="built_in">local</span>/Cellar/apache-spark/2.1.0/libexec  </div><div class="line"><span class="built_in">export</span> PATH=<span class="variable">$PATH</span>:<span class="variable">$&#123;SPARK_HOME&#125;</span>/bin</div></pre></td></tr></table></figure><h4 id="启动Spark"><a href="#启动Spark" class="headerlink" title="启动Spark"></a>启动Spark</h4><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">cd /usr/local/Cellar/apache-spark/1.6.0/bin  </div><div class="line">./start-all.sh</div></pre></td></tr></table></figure><h4 id="查看进程"><a href="#查看进程" class="headerlink" title="查看进程"></a>查看进程</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">jps</div><div class="line"></div><div class="line">6052 Worker</div><div class="line">6022 Master</div><div class="line">6728 Jps</div><div class="line">5546 NameNode</div><div class="line">5739 SecondaryNameNode</div><div class="line">5947 NodeManager</div><div class="line">5630 DataNode</div><div class="line">5855 ResourceManager</div></pre></td></tr></table></figure><h2 id="配置Pycharm开发spark应用"><a href="#配置Pycharm开发spark应用" class="headerlink" title="配置Pycharm开发spark应用"></a>配置Pycharm开发spark应用</h2><p>打开Pycharm（我的python版本是2.7）<br>新建xxxx，新建类：一个简单的wordcount<br><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</div><div class="line"></div><div class="line">logFile = <span class="string">"/Users/admin/Desktop/BackUp"</span></div><div class="line">sc = SparkContext(<span class="string">"local"</span>,<span class="string">"Simple App"</span>)</div><div class="line">logData = sc.textFile(logFile).cache()</div><div class="line"></div><div class="line">numAs = logData.filter(<span class="keyword">lambda</span> s: <span class="string">'a'</span> <span class="keyword">in</span> s).count()</div><div class="line">numBs = logData.filter(<span class="keyword">lambda</span> s: <span class="string">'b'</span> <span class="keyword">in</span> s).count()</div><div class="line"></div><div class="line">print(<span class="string">"Lines with a: %i, lines with b: %i"</span>%(numAs, numBs))</div></pre></td></tr></table></figure></p><p>F4打开当前可运行代码的配置项<br>Environment Variables 选项填写：<br><figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">PYTHONPATH    /usr/<span class="built_in">local</span>/Cellar/apache-spark/2.1.0/libexec/python</div></pre></td></tr></table></figure></p><p>至此，环境完成。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;首先，准备MacOS环境&quot;&gt;&lt;a href=&quot;#首先，准备MacOS环境&quot; class=&quot;headerlink&quot; title=&quot;首先，准备MacOS环境&quot;&gt;&lt;/a&gt;首先，准备MacOS环境&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;略过Java、Scala、Python的环境安装，从Hadoop和Spark说起
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="MacOS" scheme="http://gmle.github.io/categories/MacOS/"/>
    
    
      <category term="Hadoop" scheme="http://gmle.github.io/tags/Hadoop/"/>
    
      <category term="MacOS" scheme="http://gmle.github.io/tags/MacOS/"/>
    
      <category term="Spark" scheme="http://gmle.github.io/tags/Spark/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop_玩转 HDFS之 ACL</title>
    <link href="http://gmle.github.io/2016/09/19/%E7%8E%A9%E8%BD%ACHDFS-ACL/"/>
    <id>http://gmle.github.io/2016/09/19/玩转HDFS-ACL/</id>
    <published>2016-09-19T00:53:20.000Z</published>
    <updated>2017-05-03T06:38:39.000Z</updated>
    
    <content type="html"><![CDATA[<pre><code>Hadoop从2.4.0版本开始支持hdfs的ACL，通俗的讲就是文件访问控制权限下面对其进行一些测试：</code></pre><table><thead><tr><th>unnamed user (file owner)</th><th>文件的拥有者</th></tr></thead><tbody><tr><td>unnamed group (file group)</td><td>文件的所属组</td></tr><tr><td>named user</td><td>除了文件的拥有者和拥有组之外，的其它用户</td></tr><tr><td>named group</td><td>除了文件的拥有者和拥有组之外，的其它用户</td></tr><tr><td>mask</td><td>权限掩码，用于过滤named user和named group的权限</td></tr></tbody></table><a id="more"></a><h2 id="一、启用ACL"><a href="#一、启用ACL" class="headerlink" title="一、启用ACL"></a>一、启用ACL</h2><p>启用ACL功能</p><p>修改hdfs-site.xml 增加如下属性 开启ACL<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.permissions.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>dfs.namenode.acls.enabled<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>true<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div></pre></td></tr></table></figure></p><p>修改core-site.xml 设置用户组默认权限.<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="tag">&lt;<span class="name">property</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">name</span>&gt;</span>fs.permissions.umask-mode<span class="tag">&lt;/<span class="name">name</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">value</span>&gt;</span>002<span class="tag">&lt;/<span class="name">value</span>&gt;</span></div><div class="line"><span class="tag">&lt;/<span class="name">property</span>&gt;</span></div></pre></td></tr></table></figure></p><p>一个访问控制列表（ACL）是一组ACL词目(entries)的集合，每个ACL词目会指定一个用户/组，并赋予读/写/执行上等权限。例如：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">user::rw-</div><div class="line">   user:bruce:rwx                  #effective:r--</div><div class="line">   group::r-x                      #effective:r--</div><div class="line">   group:sales:rwx                 #effective:r--</div><div class="line">   mask::r--</div><div class="line">  other::r--</div></pre></td></tr></table></figure></p><p>这里面，没有命名的用户/组即该文件的基本所属用户/组。每一个ACL都有一个掩码(mask)，如果用户不提供掩码，那么该掩码会自动根据所有ACL条目的并集来获得(属主除外）。在该文件上运行chmod会改变掩码的权限。由于掩码用于过滤，这有效地限制了权限的扩展ACL条目，而不是仅仅改变组条目，并可能丢失的其他扩展ACL条目。</p><p>定义默认 （default）ACL条目，新的子文件和目录会自动继承默认的ACL条目设置，而只有目录会有默认的ACL条目。例如：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">user::rwx</div><div class="line">  group::r-x</div><div class="line">  other::r-x</div><div class="line">  <span class="keyword">default</span>:user::rwx</div><div class="line">  default:user:bruce:rwx #effective:r-x</div><div class="line">  <span class="keyword">default</span>:group::r-x</div><div class="line">  default:group:sales:rwx#effective:r-x</div><div class="line">  <span class="keyword">default</span>:mask::r-x</div><div class="line">  <span class="keyword">default</span>:other::r-x</div></pre></td></tr></table></figure><h3 id="ACL相关的文件API："><a href="#ACL相关的文件API：" class="headerlink" title="ACL相关的文件API："></a>ACL相关的文件API：</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">modifyAclEntries</span><span class="params">(Path path, List aclSpec)</span> <span class="keyword">throws</span> IOException</span>;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">removeAclEntries</span><span class="params">(Path path, List aclSpec)</span> <span class="keyword">throws</span> IOException</span>;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="keyword">public</span> <span class="keyword">void</span> <span class="title">removeDefaultAcl</span><span class="params">(Path path)</span> <span class="keyword">throws</span> IOException</span>;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">removeAcl</span><span class="params">(Path path)</span> <span class="keyword">throws</span> IOException</span>;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">setAcl</span><span class="params">(Path path, List aclSpec)</span> <span class="keyword">throws</span> IOException</span>;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">public</span> AclStatus <span class="title">getAclStatus</span><span class="params">(Path path)</span> <span class="keyword">throws</span> IOException</span>;</div></pre></td></tr></table></figure><h3 id="命令行命令："><a href="#命令行命令：" class="headerlink" title="命令行命令："></a>命令行命令：</h3><p>显示文件和目录的访问控制列表。如果一个目录有默认的ACL，getfacl也可以显示默认的ACL设置。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hdfs dfs -getfacl [-R] path</div></pre></td></tr></table></figure></p><p>设置文件和目录的ACL<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hdfs dfs -setfacl [-R] [-b|-k -m|-x acl_spec path]|[--set acl_spec path]</div></pre></td></tr></table></figure></p><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line">-R: Use this option to recursively list ACLs for all files and directories.</div><div class="line">-b: Revoke all permissions except the base ACLs for user, groups and others.</div><div class="line">-k: Remove the default ACL.</div><div class="line">-m: Add new permissions to the ACL with this option. Does not affect existing permissions.</div><div class="line">-x: Remove only the ACL specified.</div></pre></td></tr></table></figure><p>当ls的权限位输出以+结束时，那么该文件或目录正在启用一个ACL。<br><figure class="highlight shell"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">hdfs dfs -ls args</div></pre></td></tr></table></figure></p><h2 id="实际使用："><a href="#实际使用：" class="headerlink" title="实际使用："></a>实际使用：</h2><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div></pre></td><td class="code"><pre><div class="line"># 默认只有基本的权限控制</div><div class="line">hdfs dfs -getfacl /data</div><div class="line"># file: /data</div><div class="line"># owner: hive</div><div class="line"># group: hadoop</div><div class="line">user::rwx</div><div class="line">group::r-x</div><div class="line">other::r-x</div><div class="line">#递归显示/data下所有文件的ACL</div><div class="line">hdfs dfs -getfacl -R /data</div><div class="line"># file: /data</div><div class="line"># owner: hive</div><div class="line"># group: hadoop</div><div class="line">user::rwx</div><div class="line">group::r-x</div><div class="line">other::r-x</div><div class="line"></div><div class="line"># file: /data/test.zero</div><div class="line"># owner: hive</div><div class="line"># group: hadoop</div><div class="line">user::rw-</div><div class="line">group::r--</div><div class="line">other::r--</div><div class="line"></div><div class="line"># file: /data/test.zero.2</div><div class="line"># owner: hive</div><div class="line"># group: hadoop</div><div class="line">user::rw-</div><div class="line">group::r--</div><div class="line">other::r--</div><div class="line">#添加一个用户ACL条目</div><div class="line">hdfs dfs -setfacl -m user:hbase:rw- /data/test.zero</div><div class="line">#添加一个组ACL条目和一个用户ACL条目（如果设置一个未命名条目，可以用user::r-x，group::r-w或者other::r-x等来设置）</div><div class="line">hdfs dfs -setfacl -m group:crm:--x,user:app1:rwx /data/test.zero.2</div><div class="line">#移除一个ACL条目</div><div class="line">hdfs dfs -setfacl -x user:app1 /data/test.zero.2</div><div class="line">#“+”已开启了ACL功能</div><div class="line">hdfs dfs -ls -R /data</div><div class="line">-rw-rwxr--+  <span class="number">3</span> hive hadoop <span class="number">1073741824</span> <span class="number">2014</span>-<span class="number">12</span>-<span class="number">21</span> <span class="number">15</span>:<span class="number">32</span> /data/test.zero</div><div class="line">-rw-r-xr--+  <span class="number">3</span> hive hadoop <span class="number">1073741824</span> <span class="number">2014</span>-<span class="number">12</span>-<span class="number">21</span> <span class="number">15</span>:<span class="number">50</span> /data/test.zero.2</div><div class="line"># 查看当前ACL，此时mask已经被生成</div><div class="line">hdfs dfs -getfacl -R /data/test.zero.2</div><div class="line"># file: /data/test.zero.2</div><div class="line"># owner: hive</div><div class="line"># group: hadoop</div><div class="line">user::rw-</div><div class="line">group::r--</div><div class="line">group:crm:--x</div><div class="line">mask::r-x</div><div class="line">other::r--</div><div class="line">hdfs dfs -getfacl /data/test.zero.2</div><div class="line"># 为data目录添加default权限</div><div class="line">hdfs dfs -setfacl -m <span class="keyword">default</span>:user:debugo:rwx /data</div><div class="line">hdfs dfs -mkdir /data/d1</div><div class="line">hdfs dfs -getfacl /data/d1</div><div class="line">user::rwx</div><div class="line">user:debugo:rwx#effective:r-x</div><div class="line">group::r-x</div><div class="line">mask::r-x</div><div class="line">other::r-x</div><div class="line"><span class="keyword">default</span>:user::rwx</div><div class="line"><span class="keyword">default</span>:user:debugo:rwx</div><div class="line"><span class="keyword">default</span>:group::r-x</div><div class="line"><span class="keyword">default</span>:mask::rwx</div><div class="line"><span class="keyword">default</span>:other::r-x</div><div class="line">#可以看出，default虽然继承给了d1，但是被mask=r-x所过滤，所以这里还需要设置mask。此时debugo用户的权限可以被正常访问。</div><div class="line">hdfs dfs -setfacl -m mask::rwx /data/d1</div><div class="line">hdfs dfs -getfacl /data/d1</div><div class="line"># file: /data/d1</div><div class="line"># owner: hdfs</div><div class="line"># group: hadoop</div><div class="line">user::rwx</div><div class="line">user:debugo:rwx</div><div class="line">group::r-x</div><div class="line">mask::rwx</div><div class="line">other::r-x</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;Hadoop从2.4.0版本开始支持hdfs的ACL，
通俗的讲就是文件访问控制权限
下面对其进行一些测试：
&lt;/code&gt;&lt;/pre&gt;&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;unnamed user (file owner)&lt;/th&gt;
&lt;th&gt;文件的拥有者&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;unnamed group (file group)&lt;/td&gt;
&lt;td&gt;文件的所属组&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;named user&lt;/td&gt;
&lt;td&gt;除了文件的拥有者和拥有组之外，的其它用户&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;named group&lt;/td&gt;
&lt;td&gt;除了文件的拥有者和拥有组之外，的其它用户&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;mask&lt;/td&gt;
&lt;td&gt;权限掩码，用于过滤named user和named group的权限&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="http://gmle.github.io/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="http://gmle.github.io/tags/Hadoop/"/>
    
      <category term="HDFS" scheme="http://gmle.github.io/tags/HDFS/"/>
    
      <category term="ACL" scheme="http://gmle.github.io/tags/ACL/"/>
    
  </entry>
  
  <entry>
    <title>MapReduce架构及原理</title>
    <link href="http://gmle.github.io/2016/09/19/MapReduce%E6%9E%B6%E6%9E%84%E5%8E%9F%E7%90%86/"/>
    <id>http://gmle.github.io/2016/09/19/MapReduce架构原理/</id>
    <published>2016-09-19T00:53:20.000Z</published>
    <updated>2017-05-03T06:37:15.000Z</updated>
    
    <content type="html"><![CDATA[<pre><code>Hadoop中MapReduce的架构以及原理。</code></pre><h2 id="MapReduce介绍"><a href="#MapReduce介绍" class="headerlink" title="MapReduce介绍"></a>MapReduce介绍</h2><ul><li>MapReduce 编程模型<ul><li>Google提出的框架 主要用于搜索领域</li><li>一种分布式计算模型框架解决海量数据的计算问题</li><li>MapReduce将整个并行计算过程抽象到两个函数<ul><li>map（映射）：对一些独立元素组成的列表的每一个元素进行指定的操作，可以高度并行</li><li>Reduce（化简）：队一个列表的元素进行合并</li></ul></li><li>一个简单的MapReduce程序只需要指定map()、reduce()、input和output，剩下的事由框架来执行。</li></ul></li></ul><a id="more"></a><h2 id="MapReduce特点"><a href="#MapReduce特点" class="headerlink" title="MapReduce特点"></a>MapReduce特点</h2><pre><code>- 高容错- 高扩展- 编程简单- 适合大数据离线批量处理</code></pre><h2 id="Map任务处理"><a href="#Map任务处理" class="headerlink" title="Map任务处理"></a>Map任务处理</h2><pre><code>* 读取输入文件内容，解析成key，value对。对输入文件的没一行，解析成key，value对。每一个键值对调用一次map函数* 写自己的逻辑，处理输入的key，value，转换成新的key，value输出* 对输出的key、value进行分区* 对不同分区的数据，按照key进行排序】分组。相同的key的value放到一个集合中。</code></pre><h2 id="reduce-任务处理"><a href="#reduce-任务处理" class="headerlink" title="reduce 任务处理"></a>reduce 任务处理</h2><pre><code>* 对多个map任务的输出，按照不用的分区，通过网络copy到不同的reduce节点* 对多个map任务的输出进行合并、排序。写reduce函数自己的逻辑，对哦输入的key、value处理，转换成新的key、value输出。* 把reduce的输出保存到文件中</code></pre><p>MapReduce键值对格式：<br><img src="http://7xt0cb.com2.z0.glb.clouddn.com/mapreduce键值对格式.png" alt="键值对格式 "><br>因为会有不同的结果，所以Reduce的 v2 会是数组的形式存储多个值。</p><h2 id="MR过程中各个角色的作用："><a href="#MR过程中各个角色的作用：" class="headerlink" title="MR过程中各个角色的作用："></a>MR过程中各个角色的作用：</h2><pre><code>* jobClient：提交作业* jobTracker：初始化作业，分配作业，TaskTracker与其进行通信，协调监控整个作业* TaskTracker：定期与JobTracker通信，执行Map任务和Reduce任务* HDFS：保存作业的数据、配置、jar包、结果等。</code></pre><h2 id="作业提交流程"><a href="#作业提交流程" class="headerlink" title="作业提交流程"></a>作业提交流程</h2><pre><code>* 提交作业准备    * 编写自己的MR程序    * 配置作业，保罗输入输出路径等等* 提交作业    *配置完成后，通过JobClient提交作业* 具体功能    * 与JobTracker通信得到一个jar的存储路径和JobId    * 输入输出路径检查、讲job jar拷贝到的HDFS    * 写job.xml、真正提交作业。</code></pre><h2 id="作业初始化"><a href="#作业初始化" class="headerlink" title="作业初始化"></a>作业初始化</h2><pre><code>* 客户端提交作业后，jobTracker会讲作业加入到队列，然后进行调度，默认的是FIFO方式* 具体功能    * 作业初始化主要是指 JobInProgress中完成的    * 读取分片信息    * 创建task包括Map和Reduce创建task包括Map和Reduce任务</code></pre><p>##　任务分配</p><pre><code>* TaskTracker 与JobTracker之间的通信和任务分配是通过心跳机制实现的* TaskTracker会主动定期向JobTracker发送报告 询问是否有任务要做， 如果有，就会申请到任务</code></pre><h2 id="任务执行"><a href="#任务执行" class="headerlink" title="任务执行"></a>任务执行</h2><pre><code>* 如果TaskTracker拿到任务，会将所有信息拷贝到本地，包括代码、配置、分片信息等* TarkTacker中的localizeJob()方法会被调用进行本地化，拷贝job.jar,jobconf.job.xml到本地* TaskTracker调用launchTaskForJob()方法加载启动任务</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;Hadoop中MapReduce的架构以及原理。
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;MapReduce介绍&quot;&gt;&lt;a href=&quot;#MapReduce介绍&quot; class=&quot;headerlink&quot; title=&quot;MapReduce介绍&quot;&gt;&lt;/a&gt;MapReduce介绍&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;MapReduce 编程模型&lt;ul&gt;
&lt;li&gt;Google提出的框架 主要用于搜索领域&lt;/li&gt;
&lt;li&gt;一种分布式计算模型框架解决海量数据的计算问题&lt;/li&gt;
&lt;li&gt;MapReduce将整个并行计算过程抽象到两个函数&lt;ul&gt;
&lt;li&gt;map（映射）：对一些独立元素组成的列表的每一个元素进行指定的操作，可以高度并行&lt;/li&gt;
&lt;li&gt;Reduce（化简）：队一个列表的元素进行合并&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;一个简单的MapReduce程序只需要指定map()、reduce()、input和output，剩下的事由框架来执行。&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="http://gmle.github.io/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="http://gmle.github.io/tags/Hadoop/"/>
    
      <category term="MapReduce" scheme="http://gmle.github.io/tags/MapReduce/"/>
    
      <category term="架构" scheme="http://gmle.github.io/tags/%E6%9E%B6%E6%9E%84/"/>
    
      <category term="原理" scheme="http://gmle.github.io/tags/%E5%8E%9F%E7%90%86/"/>
    
  </entry>
  
  <entry>
    <title>HBase入门 — 操作数据表</title>
    <link href="http://gmle.github.io/2016/09/19/HBase%E5%85%A5%E9%97%A8_%E6%93%8D%E4%BD%9C%E6%95%B0%E6%8D%AE/"/>
    <id>http://gmle.github.io/2016/09/19/HBase入门_操作数据/</id>
    <published>2016-09-19T00:53:20.000Z</published>
    <updated>2017-05-03T06:37:52.000Z</updated>
    
    <content type="html"><![CDATA[<pre><code>HBase中数据表的增删改查其实底层还是最普通的MR(MapReduce)操作。</code></pre><h3 id="Source"><a href="#Source" class="headerlink" title="Source"></a>Source</h3><p><a href="https://github.com/gmle/hbase" target="_blank" rel="external">源码地址 GitHub/hbase</a></p><a id="more"></a><h2 id="Compile-environment"><a href="#Compile-environment" class="headerlink" title="Compile environment"></a>Compile environment</h2><pre><code>Oracle JDK_1.8</code></pre><h2 id="create-table"><a href="#create-table" class="headerlink" title="create table:"></a>create table:</h2><p>Position: cn.lesion.operateTable.Create_Table;<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Create_Table</span> </span>&#123;</div><div class="line">...</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><h2 id="drop-table"><a href="#drop-table" class="headerlink" title="drop table"></a>drop table</h2><p>Position: cn.lesion.operateTable.Drop_Table;<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Drop_Table</span> </span>&#123;</div><div class="line">...</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><h2 id="delete-data"><a href="#delete-data" class="headerlink" title="delete data"></a>delete data</h2><p>Position: cn.lesion.operateTable.Delete_Data;<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Delete_Data</span> </span>&#123;</div><div class="line">...</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><h2 id="Insert-Data"><a href="#Insert-Data" class="headerlink" title="Insert Data"></a>Insert Data</h2><p>Position: cn.lesion.operateTable.Insert_Data;<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Insert_Data</span> </span>&#123;</div><div class="line">...</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><h2 id="Query-Data"><a href="#Query-Data" class="headerlink" title="Query Data"></a>Query Data</h2><p>Position: cn.lesion.operateTable.Query_Data;<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Query_Data</span> </span>&#123;</div><div class="line">...</div><div class="line">&#125;</div></pre></td></tr></table></figure></p>]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;HBase中数据表的增删改查
其实底层还是最普通的MR(MapReduce)操作。
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;Source&quot;&gt;&lt;a href=&quot;#Source&quot; class=&quot;headerlink&quot; title=&quot;Source&quot;&gt;&lt;/a&gt;Source&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;https://github.com/gmle/hbase&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;源码地址 GitHub/hbase&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="HBase" scheme="http://gmle.github.io/categories/HBase/"/>
    
    
      <category term="Hadoop" scheme="http://gmle.github.io/tags/Hadoop/"/>
    
      <category term="HBase" scheme="http://gmle.github.io/tags/HBase/"/>
    
      <category term="CRUD" scheme="http://gmle.github.io/tags/CRUD/"/>
    
  </entry>
  
  <entry>
    <title>HBase的列簇</title>
    <link href="http://gmle.github.io/2016/09/19/HBase%E7%9A%84%E5%88%97%E7%B0%87/"/>
    <id>http://gmle.github.io/2016/09/19/HBase的列簇/</id>
    <published>2016-09-19T00:53:20.000Z</published>
    <updated>2017-05-03T06:38:13.000Z</updated>
    
    <content type="html"><![CDATA[<pre><code>对于HBase中的列簇，新手都会有这样的问题HBase的列有列族前缀和列组成，那么一个表中列族要怎么设定？是只设定一个？还是越多越好？还是根据什么设定几个？</code></pre><a id="more"></a><h2 id="何时用HBase"><a href="#何时用HBase" class="headerlink" title="何时用HBase"></a>何时用HBase</h2><pre><code>1.系统需要适应不同种类的数据格式和数据源，不能预先严格定义模式，需要处理大规模数据；2.不强调数据之间的关系，所要存储的数据是半结构化或非结构化的；3.数据非常稀疏；4.想要更好的进行扩展；</code></pre><p>比如谷歌就将BigTable用来存储网页的索引数据，索引数据就很好的满足了上面的几点要求。</p><h2 id="HBase的结构"><a href="#HBase的结构" class="headerlink" title="HBase的结构"></a>HBase的结构</h2><pre><code>表、行、列和单元格    先做一个简单的总结：最基本的单位是列（column），一列或者多列组成一行（row），并且由唯一的行键（row key）来确定存储。    一个表中有很多行，每一列可能有多个版本，在每一个单元格（Cell）中存储了不同的值。    HBase的行与行之间是有序的，按照row key的字典序进行排序，行键是唯一的，在一个表里只出现一次，否则就是在更新同一行，行键可以是任意的字节数组。    一行由若干列组成，其中的某些列又可以构成一个列族（column family），一个列族的所有列存储在同一个底层的存储文件里，这个文件称之为HFile。    列族需要在创建表的时候就定义好，数量也不宜过多。    列族名必须由可打印字符组成，创建表的时候不需要定义好列。    对列的引用格式通常为family：qualifier，qualifier也可以是任意的字节数组。    同一个列族里qualifier的名称应该唯一，否则就是在更新同一列，列的数量没有限制，可以有数百万个。    列值也没有类型和长度限定。    HBase会对row key的长度做检查，默认应该小于65536。</code></pre><p>一个可视化的HBase表如下：<br><img src="http://7xt0cb.com2.z0.glb.clouddn.com/HBase%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%9B%BE%E8%A1%A8.jpg" alt="可视化HBase表"></p><p>Timestamp代表时间戳，默认由系统指定，用户也可以显示设置。使用不同的时间戳来区分不同的版本。一个单元格的不同版本的值按照时间戳降序排列在一起，在读取的时候优先取最新的值。用户可以指定每个值能保存的最大版本数.</p><p>HBase的存取模式如下（表，行键，列族，列，时间戳）-&gt; 值。即一个表中的某一行键的某一列族的某一列的某一个版本的值唯一。</p><p>行数据的存取操作是原子的，可以读取任意数目的列。目前还不支持跨行事务和跨表事务。</p><p>同一列族下的数据压缩在一起，访问控制磁盘和内存都在列族层面进行。</p><p>2.自动分区<br>    HBase中扩展和负载均衡的基本单元称作region，region本质上是以行键排序的连续存储空间。如果region过大，系统就会把它们动态拆分，相反的，就把多个region合并，以减少存储文件数量。<br>    一个表最开始只有一个region，用户开始向表中插入数据时，系统会检查region大小，确保不会超过配置的最大值，如果超过，会从region中行键的中间值一分为二，将该region分为大小大致相等的两个region。</p><p>3.存储格式<br>    HFile：HBase中KeyValue数据的存储格式。HFile是Hadoop的二进制格式文件。<br>    HLog：HBase中WAL（Write-Ahead-Log，预写式日志）文件的存储格式，物理上是Hadoop的Sequence File。</p><p>HFile的格式如下图：<br><img src="http://img.blog.csdn.net/20140731145136723" alt="HFile的存储格式"></p><p>HFile文件的长度可变，唯一固定的是File Info和Trailer。Trailer存储指向其他块的指针，它在持久化数据到文件结束时写入的，写入后，该文件就会变成不可变的数据存储文件。数据块（data blocks）中存储key-values，可以看做是一个MapFile。当block关闭操作时，第一个key会被写入index中，index文件在hfile关闭操作时写入。</p><p>KeyValue的具体格式如下图：<br><img src="http://img.blog.csdn.net/20140731145347373" alt="key-value"></p><p>上图中，keytype有四种类型，分别是Put、Delete、 DeleteColumn和DeleteFamily。RowLength为2个字节，Row长度不固定，ColumnFamilyLength为2个字节，ColumnFamily长度不固定，ColumnQualifier长度不固定，TimeStamp为4个字节，KeyType为1个字节。之所以不记录ColumnQualifier的长度是因为可以通过其他字段计算得到。</p><h2 id="HBase常用操作："><a href="#HBase常用操作：" class="headerlink" title="HBase常用操作："></a>HBase常用操作：</h2><p>List；<br>Create；<br>Put；<br>Scan；<br>Get；<br>Delete；<br>Disable；<br>Drop；</p><h2 id="列簇的设计"><a href="#列簇的设计" class="headerlink" title="列簇的设计"></a>列簇的设计</h2><pre><code>1、列簇的设计需要根据你的业务。那些可能被反复修改的数据表尽量使用单列簇。每个列簇在HDFS都有一个独立的HFILE，当某个ROWKEY的某个列簇数据被冲刷时，这个ROWKEY连带的其他列簇数据也会被一起冲刷，I/O负担很大。APACHE官方也提倡多列簇的设计方案，单列簇性能是最高的。而持久型数据，也就是一次写入，从不修改的数据，可以使用多列簇，原理相同，但目前任然提倡单列簇设计模式2、多列簇的效率问题参照13、所谓列簇分组，就相当于关系习惯数据库中，两个表被纵向合并，形成一张双列簇的表</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;对于HBase中的列簇，新手都会有这样的问题
HBase的列有列族前缀和列组成，
那么一个表中列族要怎么设定？
是只设定一个？还是越多越好？还是根据什么设定几个？
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="HBase" scheme="http://gmle.github.io/categories/HBase/"/>
    
    
      <category term="Hadoop" scheme="http://gmle.github.io/tags/Hadoop/"/>
    
      <category term="HBase" scheme="http://gmle.github.io/tags/HBase/"/>
    
      <category term="列族" scheme="http://gmle.github.io/tags/%E5%88%97%E6%97%8F/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop_Yarn架构详解</title>
    <link href="http://gmle.github.io/2016/09/19/Yarn%E6%9E%B6%E6%9E%84%E8%AF%A6%E8%A7%A3/"/>
    <id>http://gmle.github.io/2016/09/19/Yarn架构详解/</id>
    <published>2016-09-19T00:53:20.000Z</published>
    <updated>2017-05-03T06:37:01.000Z</updated>
    
    <content type="html"><![CDATA[<pre><code>Yarn架构概述Yarn Shell操作Yarn 高可用的配置</code></pre><h2 id="Yarn-架构概述"><a href="#Yarn-架构概述" class="headerlink" title="Yarn 架构概述"></a>Yarn 架构概述</h2><pre><code>* 直接源于MRv1的缺陷(原MapReduce框架的不足)    * JobTracker是集群事务的集中处理点，存在单点故障(一个失败，全部受影响)    * JobTracker需要完成的任务太多，既要维护job的状态又要维护job的task的状态，造成过多的资源消耗(扩展性受限)</code></pre><a id="more"></a><pre><code>* 在taskTracker端，用map/reduce task作为资源的表示过于简单，没有考虑到cpu、内存等资源情况，当把两个需要消耗大内存的task调度到一起，很容易出现OOM* 把资源强制划分为map/reduce slot,当只有map task时，reduce slot不能用；当只有reduce task时，map slot不能用，容易造成资源利用不足。(多计算框架各自为战，数据共享困难).</code></pre><h3 id="Hadoop-Yarn基本架构"><a href="#Hadoop-Yarn基本架构" class="headerlink" title="Hadoop Yarn基本架构"></a>Hadoop Yarn基本架构</h3><pre><code>* Yarn 各模块组成    * ResourceManager        * 处理客户端请求        * 启动/监控ApplicationMaster        * 监控NodeManager        * 资源分配与调度    * NodeManager        * 单个节点上的资源管理        * 处理来自ResourceManager的名年龄        * 处理来自ApplicationMaster的命令    * ApplicationMaster        * 数据切分        * 为应用程序申请资源，并分配给内部任务        * 任务监控与容错* Yarn的容错    * ResourceManager        * 存在单点故障        * 2.X版本基于ZooKeeper实现HA    * NodeManager        * 失败后，RM将失败任务告诉对应的AM        * AM决定如何处理失败的任务    * ApplicationMaster        * 失败后，由RM负责重启，AM需处理内部任务的容错问题- Hadoop Yarn调度框架    * 双层电镀框架        * RM将资源分配给AM        * AM讲资源进一步分配给各个Task    * 基于资源预留的调度策略        * 资源不足时，会为Task预留，知道资源充足        * 与“all or nothing”策略不同（Apache Mesos）    * HadoopYarn资源调度器        * 多类型资源调度            * 采用DRF算法            * 目前只支持CPU和内存两种资源        * 提供多种资源调度器            * FIFO：先进先出            * Fair Scheduler：公平调度器            * Capacity Scheduler：容量调度器            * 多租户资源调度器                * 支持资源按比例分配                * 支持层级队列划分方式                * 支持资源抢占    * Hadoop Yarn 的资源隔离方案        * 支持内存和CPU两种资源隔离            * 内存是一种 “决定生死`” 的资源(集群内存不够，内存一处，任务崩溃)            * CPU是一种 “你更想快慢” 的资源        * 内存隔离            * 基于县城监控的方案            * 基于Cgroups的方案        * CPU隔离            * 默认不对CPu资源进行隔离            * 基于Cgroups的方案    * Hadoop Yarn资源调度语义        * 支持的语义            * 请求某个铁定节点/机架上的特定资源量            * 讲某些节点加入或移除黑名单，不再自己分配这些节点上的资源            * 请求归还某些资源        * 部支持的语义            * 请求任意节点/机架上的特定资源量            * 请求一组或几组符合某种特质的资源            * 超细粒度资源            * 动态调整Container资源* 运行在Yarn上的计算框架    * 离线计算框架：MapReduce（处理海量数据）    * DAG计算框架：Tez    * 流式计算框架：Storm：（处理流式数据）    * 内存计算框架：Spark（因为基于内存处理，所以特别快）    * 图计算框架：Giraph、GraphLib</code></pre><h3 id="运行在Yarn上的计算框架-MapReduce-Spark-AM"><a href="#运行在Yarn上的计算框架-MapReduce-Spark-AM" class="headerlink" title="运行在Yarn上的计算框架(MapReduce, Spark)AM"></a>运行在Yarn上的计算框架(MapReduce, Spark)AM</h3><pre><code>* 框架    * 离线计算框架：MapReduce（处理海量数据）    * DAG计算框架：Tez    * 流式计算框架：Storm：（处理流式数据）    * 内存计算框架：Spark（因为基于内存处理，所以特别快）    * 图计算框架：Giraph、GraphLib* Yarn应用程序类型    * 长应用程序        * Service、HTTP Server等    * 短应用程序        * MR job、Spark Job等。</code></pre><h3 id="Yarn-的发展前景"><a href="#Yarn-的发展前景" class="headerlink" title="Yarn 的发展前景"></a>Yarn 的发展前景</h3><pre><code>* 服务自动化部署（集群一键安装）* 调度框架的完善    * 支持更多的资源类型（网络、磁盘等）    * 支持更多的调度语义* 长作业的在线升级    * storm的在吸纳升级    * Container资源动态调整* 容错机制    * ResourceMapager自身容错    * NOdeManager宕机，任务不受影响    * ApplicationMaster个性化容错</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;Yarn架构概述
Yarn Shell操作
Yarn 高可用的配置
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;Yarn-架构概述&quot;&gt;&lt;a href=&quot;#Yarn-架构概述&quot; class=&quot;headerlink&quot; title=&quot;Yarn 架构概述&quot;&gt;&lt;/a&gt;Yarn 架构概述&lt;/h2&gt;&lt;pre&gt;&lt;code&gt;* 直接源于MRv1的缺陷(原MapReduce框架的不足)
    * JobTracker是集群事务的集中处理点，存在单点故障(一个失败，全部受影响)
    * JobTracker需要完成的任务太多，既要维护job的状态又要维护job的task的状态，造成过多的资源消耗(扩展性受限)
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="http://gmle.github.io/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="http://gmle.github.io/tags/Hadoop/"/>
    
      <category term="Yarn" scheme="http://gmle.github.io/tags/Yarn/"/>
    
  </entry>
  
  <entry>
    <title>HBase的Java API</title>
    <link href="http://gmle.github.io/2016/09/19/HBase%E7%9A%84JavaAPI%E8%AF%A6%E8%A7%A3/"/>
    <id>http://gmle.github.io/2016/09/19/HBase的JavaAPI详解/</id>
    <published>2016-09-19T00:53:20.000Z</published>
    <updated>2017-05-03T06:37:57.000Z</updated>
    
    <content type="html"><![CDATA[<pre><code>HBase的常用Java API</code></pre><a id="more"></a><h2 id="HBase常用操作："><a href="#HBase常用操作：" class="headerlink" title="HBase常用操作："></a>HBase常用操作：</h2><p>List；<br>Create；<br>Put；<br>Scan；<br>Get；<br>Delete；<br>Disable；<br>Drop；</p><h1 id="Java-API的HBase操作实现"><a href="#Java-API的HBase操作实现" class="headerlink" title="Java API的HBase操作实现"></a>Java API的HBase操作实现</h1><p>可以查看前面几篇文章了解下HBase的体系结构和HBase数据视图。</p><h2 id="连接HBase，配置必要的配置文件"><a href="#连接HBase，配置必要的配置文件" class="headerlink" title="连接HBase，配置必要的配置文件"></a>连接HBase，配置必要的配置文件</h2><p>HBaseConfiguration是每一个hbase client都会使用到的对象，它代表的是HBase配置信息。它有两种构造方式：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">HBaseConfiguration</span><span class="params">()</span></span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">HBaseConfiguration</span><span class="params">(<span class="keyword">final</span> Configuration c)</span></span></div></pre></td></tr></table></figure></p><p>默认的构造方式会尝试从hbase-default.xml和hbase-site.xml中读取配置。<br>也可以指定位置去读取<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">public</span> <span class="keyword">static</span> Configuration config = <span class="keyword">new</span> Configuration();</div><div class="line">  <span class="keyword">static</span> &#123;</div><div class="line">      config.addResource(<span class="string">"/conf/hbase-site.xml"</span>);</div><div class="line">  &#125;</div></pre></td></tr></table></figure></p><p>如果classpath没有这两个文件，就需要你自己设置配置。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">Configuration config = <span class="keyword">new</span> Configuration();</div><div class="line"></div><div class="line">config.set(“hbase.zookeeper.quorum”, “zkServer”);</div><div class="line">config.set(“hbase.zookeeper.property.clientPort”, “<span class="number">2181</span>″);\</div><div class="line"></div><div class="line">iguration config = <span class="keyword">new</span> HBaseConfiguration(config);</div></pre></td></tr></table></figure><h2 id="建表"><a href="#建表" class="headerlink" title="建表"></a>建表</h2><p>首先加入配置文件</p><p>创建表是通过HBaseAdmin对象来操作的。HBaseAdmin负责表的META信息处理。HBaseAdmin提供了createTable这个方法：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">createTable</span><span class="params">(HTableDescriptor desc)</span></span></div></pre></td></tr></table></figure><p>HTableDescriptor 代表的是表的schema, 提供的方法中比较有用的有setMaxFileSize，指定最大的region size</p><p>setMemStoreFlushSize 指定memstore flush到HDFS上的文件大小</p><p>增加列簇，也就是增加family。<br>通过 addFamily方法<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">addFamily</span><span class="params">(<span class="keyword">final</span> HColumnDescriptor family)</span></span></div></pre></td></tr></table></figure></p><p>HColumnDescriptor 代表的是column的schema，提供的方法比较常用的有</p><p>setTimeToLive:指定最大的TTL,单位是ms,过期数据会被自动删除。</p><p>setInMemory:指定是否放在内存中，对小表有用，可用于提高效率。默认关闭</p><p>setBloomFilter:指定是否使用BloomFilter,可提高随机查询效率。默认关闭</p><p>setCompressionType:设定数据压缩类型。默认无压缩。</p><p>setMaxVersions:指定数据最大保存的版本个数。默认为3。</p><h3 id="简单的例子–-gt-创建含有两个列簇的表"><a href="#简单的例子–-gt-创建含有两个列簇的表" class="headerlink" title="简单的例子–&gt; 创建含有两个列簇的表"></a>简单的例子–&gt; 创建含有两个列簇的表</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> cn.lesion.MyPractice;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.HColumnDescriptor;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.HTableDescriptor;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.HBaseAdmin;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"><span class="comment"> * Created in Intellij IDEA .</span></div><div class="line"><span class="comment"> * Author: 王乐.</span></div><div class="line"><span class="comment"> * Date  : 16-5-4.</span></div><div class="line"><span class="comment"> */</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Create</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="comment">//定义静态常量</span></div><div class="line">    <span class="keyword">public</span> <span class="keyword">static</span> Configuration config = <span class="keyword">new</span> Configuration();</div><div class="line"></div><div class="line">    <span class="keyword">static</span> &#123;</div><div class="line">        config.addResource(<span class="string">"/conf/hbase-site.xml"</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">createTable</span><span class="params">(String tableName)</span></span>&#123;</div><div class="line"></div><div class="line">        System.out.println(<span class="string">"开始建表"</span>);</div><div class="line"></div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            HBaseAdmin admin = <span class="keyword">new</span> HBaseAdmin(config);</div><div class="line"></div><div class="line">            <span class="comment">//如果创建的这个表存在的话，删除此表</span></div><div class="line">            <span class="keyword">if</span> (admin.tableExists(tableName)) &#123;</div><div class="line">                <span class="comment">//禁用此表</span></div><div class="line">                admin.disableTable(tableName);</div><div class="line">                <span class="comment">//删除这个表</span></div><div class="line">                System.out.println(<span class="string">"表已经存在，开始删除这个存在的表..."</span>);</div><div class="line">                admin.deleteTable(tableName);</div><div class="line">                System.out.println(<span class="string">"删除表 "</span>+tableName+<span class="string">" 成功！"</span>);</div><div class="line"></div><div class="line">            &#125;</div><div class="line"></div><div class="line">            <span class="comment">//对象：列族（Column Family)</span></div><div class="line">            HTableDescriptor tableDescriptor = <span class="keyword">new</span> HTableDescriptor(tableName);</div><div class="line">            tableDescriptor.addFamily(<span class="keyword">new</span> HColumnDescriptor(<span class="string">"info"</span>));</div><div class="line">            tableDescriptor.addFamily(<span class="keyword">new</span> HColumnDescriptor(<span class="string">"message"</span>));</div><div class="line"></div><div class="line">            <span class="comment">//创建含有两个列簇的表</span></div><div class="line">            admin.createTable(tableDescriptor);</div><div class="line"></div><div class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">            System.out.println(<span class="string">"Not Found config"</span>);</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        createTable(<span class="string">"mytable"</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure><h2 id="删除表"><a href="#删除表" class="headerlink" title="删除表"></a>删除表</h2><p>删除表也是通过HBaseAdmin来操作。<br>删除表之前首先要disable表。这是一个非常耗时的操作，所以不建议频繁删除表。<br>删除表之前要先禁用这个表：方法：disableTable<br>然后进行删除操作：方法:delete</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> cn.lesion.operateTable;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.MasterNotRunningException;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.ZooKeeperConnectionException;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.HBaseAdmin;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"><span class="comment"> * Created in Intellij IDEA .</span></div><div class="line"><span class="comment"> * Author : 王乐.</span></div><div class="line"><span class="comment"> * Date : 2016.05.03.21.</span></div><div class="line"><span class="comment"> */</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Drop_Table</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Configuration config = <span class="keyword">new</span> Configuration();</div><div class="line"></div><div class="line">    <span class="comment">//Loading configuration files on startup！</span></div><div class="line">    <span class="keyword">static</span> &#123;</div><div class="line">        <span class="comment">//add Create_Table config</span></div><div class="line">        config.addResource(<span class="string">"/conf/hbase-site.xml"</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        dropTable(<span class="string">"hbase_test1"</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line"><span class="comment">     * According to table's name to Drop table</span></div><div class="line"><span class="comment">     * <span class="doctag">@param</span> tableName</span></div><div class="line"><span class="comment">     */</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">dropTable</span><span class="params">(String tableName)</span> </span>&#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            HBaseAdmin admin = <span class="keyword">new</span> HBaseAdmin(config);</div><div class="line"></div><div class="line">            System.out.println(<span class="string">"Deleting “ "</span> + tableName + <span class="string">" ”..."</span>);</div><div class="line"></div><div class="line">            admin.disableTable(tableName);</div><div class="line">            admin.deleteTable(tableName);</div><div class="line"></div><div class="line">            System.out.println(<span class="string">"Table“ "</span> + tableName + <span class="string">" ”delete success"</span>);</div><div class="line"></div><div class="line">        &#125; <span class="keyword">catch</span> (MasterNotRunningException e) &#123;</div><div class="line"></div><div class="line">            System.out.println(<span class="string">"HBase service no start！"</span>);</div><div class="line"></div><div class="line">        &#125; <span class="keyword">catch</span> (ZooKeeperConnectionException e) &#123;</div><div class="line"></div><div class="line">            System.out.println(<span class="string">"Not connected to zookeeper!"</span>);</div><div class="line"></div><div class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</div><div class="line"></div><div class="line">            System.out.println(<span class="string">"Not found config!"</span>);;</div><div class="line"></div><div class="line">        &#125;</div><div class="line"></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure><h2 id="查询数据"><a href="#查询数据" class="headerlink" title="查询数据"></a>查询数据</h2><p>查询分为单条随机查询和批量查询。</p><p>单条查询是通过rowkey在table中查询某一行的数据。HTable提供了get方法来完成单条查询。</p><p>批量查询是通过制定一段rowkey的范围来查询。HTable提供了个getScanner方法来完成批量查询。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> Result <span class="title">get</span><span class="params">(<span class="keyword">final</span> Get get)</span></span></div><div class="line"><span class="function"><span class="keyword">public</span> ResultScanner <span class="title">getScanner</span><span class="params">(<span class="keyword">final</span> Scan scan)</span></span></div></pre></td></tr></table></figure><p>Get对象包含了一个Get查询需要的信息。它的构造方法有两种：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">Get</span><span class="params">(<span class="keyword">byte</span> [] row)</span></span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">Get</span><span class="params">(<span class="keyword">byte</span> [] row, RowLock rowLock)</span></span></div></pre></td></tr></table></figure><p>Rowlock是为了保证读写的原子性，你可以传递一个已经存在Rowlock，否则HBase会自动生成一个新的rowlock。</p><p>Scan对象提供了默认构造函数，一般使用默认构造函数。</p><p>setMaxVersions:指定最大的版本个数。如果不带任何参数调用setMaxVersions,表示取所有的版本。如果不掉用setMaxVersions,只会取到最新的版本。</p><p>setTimeRange:指定最大的时间戳和最小的时间戳，只有在此范围内的cell才能被获取。</p><p>setTimeStamp:指定时间戳。</p><p>setFilter:指定Filter来过滤掉不需要的信息</p><p>Scan特有的方法：</p><p>setStartRow:指定开始的行。如果不调用，则从表头开始。</p><p>setStopRow:指定结束的行（不含此行）。</p><p>setBatch:指定最多返回的Cell数目。用于防止一行中有过多的数据，导致OutofMemory错误。</p><p>ResultScanner是Result的一个容器，每次调用ResultScanner的next方法，会返回Result.<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> Result <span class="title">next</span><span class="params">()</span> <span class="keyword">throws</span> IOException</span>;</div><div class="line"><span class="keyword">public</span> Result [] next(<span class="keyword">int</span> nbRows) <span class="keyword">throws</span> IOException;</div></pre></td></tr></table></figure></p><p>Result代表是一行的数据。常用方法有：</p><p>getRow:返回rowkey</p><p>raw:返回所有的key value数组。</p><p>getValue:按照column来获取cell的值</p><p>示例：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> cn.lesion.operateTable;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.KeyValue;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.*;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.filter.CompareFilter.CompareOp;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.filter.Filter;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.filter.FilterList;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.filter.SingleColumnValueFilter;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.util.Bytes;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.util.ArrayList;</div><div class="line"><span class="keyword">import</span> java.util.List;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"><span class="comment"> * Created in Intellij IDEA .</span></div><div class="line"><span class="comment"> * Author : 王乐.</span></div><div class="line"><span class="comment"> * Date : 2016.05.03.21.</span></div><div class="line"><span class="comment"> */</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Query_Data</span> </span>&#123;</div><div class="line"></div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Configuration config = <span class="keyword">new</span> Configuration();</div><div class="line"></div><div class="line">    <span class="comment">//Loading configuration files on startup！</span></div><div class="line">    <span class="keyword">static</span> &#123;</div><div class="line">        <span class="comment">//add Create_Table config</span></div><div class="line">        config.addResource(<span class="string">"/conf/hbase-site.xml"</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        <span class="comment">// QueryAll("hbase_test");</span></div><div class="line">        <span class="comment">// QueryByRowKey("hbase_test");</span></div><div class="line">        <span class="comment">// QueryByCondition("hbase_test");</span></div><div class="line">        QueryByMultiCondition(<span class="string">"hbase_test"</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line"><span class="comment">     * Query all data</span></div><div class="line"><span class="comment">     * <span class="doctag">@param</span> tableName</span></div><div class="line"><span class="comment">     */</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">QueryAll</span><span class="params">(String tableName)</span> </span>&#123;</div><div class="line">        HTablePool pool = <span class="keyword">new</span> HTablePool(config, <span class="number">1000</span>);</div><div class="line">        HTableInterface table = pool.getTable(tableName);</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            ResultScanner rs = table.getScanner(<span class="keyword">new</span> Scan());</div><div class="line">            <span class="keyword">for</span> (Result r : rs) &#123;</div><div class="line">                System.out.println(<span class="string">"get the rowkey:"</span> + <span class="keyword">new</span> String(r.getRow()));</div><div class="line">                <span class="keyword">for</span> (KeyValue keyValue : r.raw()) &#123;</div><div class="line">                    System.out.println(<span class="string">"列："</span> + <span class="keyword">new</span> String(keyValue.getFamily())</div><div class="line">                            + <span class="string">"====value:"</span> + <span class="keyword">new</span> String(keyValue.getValue()));</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line"><span class="comment">     * 单条件查询,根据rowkey查询唯一一条记录</span></div><div class="line"><span class="comment">     * Single condition query,According to rowkey query data</span></div><div class="line"><span class="comment">     * <span class="doctag">@param</span> tableName</span></div><div class="line"><span class="comment">     */</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">QueryByRowKey</span><span class="params">(String tableName)</span> </span>&#123;</div><div class="line"></div><div class="line">        HTablePool pool = <span class="keyword">new</span> HTablePool(config, <span class="number">1000</span>);</div><div class="line">        HTableInterface table = pool.getTable(tableName);</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            <span class="comment">// Add the rowkey  or Can be defined in the parameter</span></div><div class="line">            Get scan = <span class="keyword">new</span> Get(<span class="string">"112233bbbcccc"</span>.getBytes());<span class="comment">// 根据rowkey查询</span></div><div class="line">            Result r = table.get(scan);</div><div class="line">            System.out.println(<span class="string">"获得到rowkey:"</span> + <span class="keyword">new</span> String(r.getRow()));</div><div class="line">            <span class="keyword">for</span> (KeyValue keyValue : r.raw()) &#123;</div><div class="line">                System.out.println(<span class="string">"列："</span> + <span class="keyword">new</span> String(keyValue.getFamily())</div><div class="line">                        + <span class="string">"====值:"</span> + <span class="keyword">new</span> String(keyValue.getValue()));</div><div class="line">            &#125;</div><div class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line">    &#125;</div><div class="line"></div><div class="line"></div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line"><span class="comment">     * 单条件查询，查询多条记录</span></div><div class="line"><span class="comment">     * Single condition query, query multiple records</span></div><div class="line"><span class="comment">     * <span class="doctag">@param</span> tableName</span></div><div class="line"><span class="comment">     */</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">QueryByCondition</span><span class="params">(String tableName)</span> </span>&#123;</div><div class="line"></div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            HTablePool pool = <span class="keyword">new</span> HTablePool(config, <span class="number">1000</span>);</div><div class="line">            HTableInterface table = pool.getTable(tableName);</div><div class="line"></div><div class="line">            <span class="comment">// 当列column1的值为aaa时进行查询</span></div><div class="line">            <span class="comment">//Query when the value of the column column1 is aaa</span></div><div class="line">            Filter filter = <span class="keyword">new</span> SingleColumnValueFilter(Bytes</div><div class="line">                    .toBytes(<span class="string">"column1"</span>), <span class="keyword">null</span>, CompareOp.EQUAL, Bytes</div><div class="line">                    .toBytes(<span class="string">"aaa"</span>));</div><div class="line"></div><div class="line"></div><div class="line">            Scan s = <span class="keyword">new</span> Scan();</div><div class="line">            s.setFilter(filter);</div><div class="line">            ResultScanner rs = table.getScanner(s);</div><div class="line">            <span class="keyword">for</span> (Result r : rs) &#123;</div><div class="line">                System.out.println(<span class="string">"Get rowkey:"</span> + <span class="keyword">new</span> String(r.getRow()));</div><div class="line">                <span class="keyword">for</span> (KeyValue keyValue : r.raw()) &#123;</div><div class="line">                    System.out.println(<span class="string">"column："</span> + <span class="keyword">new</span> String(keyValue.getFamily())</div><div class="line">                            + <span class="string">"====value:"</span> + <span class="keyword">new</span> String(keyValue.getValue()));</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line"><span class="comment">     * 组合条件查询</span></div><div class="line"><span class="comment">     * Combination condition query</span></div><div class="line"><span class="comment">     * <span class="doctag">@param</span> tableName</span></div><div class="line"><span class="comment">     */</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">QueryByMultiCondition</span><span class="params">(String tableName)</span> </span>&#123;</div><div class="line"></div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            HTablePool pool = <span class="keyword">new</span> HTablePool(config, <span class="number">1000</span>);</div><div class="line">            HTableInterface table = pool.getTable(tableName);</div><div class="line"></div><div class="line">            List&lt;Filter&gt; filters = <span class="keyword">new</span> ArrayList&lt;Filter&gt;();</div><div class="line"></div><div class="line">            Filter filter1 = <span class="keyword">new</span> SingleColumnValueFilter(Bytes</div><div class="line">                    .toBytes(<span class="string">"column1"</span>), <span class="keyword">null</span>, CompareOp.EQUAL, Bytes</div><div class="line">                    .toBytes(<span class="string">"aaa"</span>));</div><div class="line">            filters.add(filter1);</div><div class="line"></div><div class="line">            Filter filter2 = <span class="keyword">new</span> SingleColumnValueFilter(Bytes</div><div class="line">                    .toBytes(<span class="string">"column2"</span>), <span class="keyword">null</span>, CompareOp.EQUAL, Bytes</div><div class="line">                    .toBytes(<span class="string">"bbb"</span>));</div><div class="line">            filters.add(filter2);</div><div class="line"></div><div class="line">            Filter filter3 = <span class="keyword">new</span> SingleColumnValueFilter(Bytes</div><div class="line">                    .toBytes(<span class="string">"column3"</span>), <span class="keyword">null</span>, CompareOp.EQUAL, Bytes</div><div class="line">                    .toBytes(<span class="string">"ccc"</span>));</div><div class="line">            filters.add(filter3);</div><div class="line"></div><div class="line">            FilterList filterList1 = <span class="keyword">new</span> FilterList(filters);</div><div class="line"></div><div class="line">            Scan scan = <span class="keyword">new</span> Scan();</div><div class="line">            scan.setFilter(filterList1);</div><div class="line">            ResultScanner rs = table.getScanner(scan);</div><div class="line">            <span class="keyword">for</span> (Result r : rs) &#123;</div><div class="line">                System.out.println(<span class="string">"Get rowkey:"</span> + <span class="keyword">new</span> String(r.getRow()));</div><div class="line">                <span class="keyword">for</span> (KeyValue keyValue : r.raw()) &#123;</div><div class="line">                    System.out.println(<span class="string">"column："</span> + <span class="keyword">new</span> String(keyValue.getFamily())</div><div class="line">                            + <span class="string">"====value:"</span> + <span class="keyword">new</span> String(keyValue.getValue()));</div><div class="line">                &#125;</div><div class="line">            &#125;</div><div class="line">            rs.close();</div><div class="line"></div><div class="line">        &#125; <span class="keyword">catch</span> (Exception e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure></p><h2 id="插入数据"><a href="#插入数据" class="headerlink" title="插入数据"></a>插入数据</h2><p>HTable通过put方法来插入数据。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">(<span class="keyword">final</span> Put put)</span> <span class="keyword">throws</span> IOException</span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">put</span><span class="params">(<span class="keyword">final</span> List puts)</span> <span class="keyword">throws</span> IOException</span></div></pre></td></tr></table></figure><p>可以传递单个批Put对象或者List put对象来分别实现单条插入和批量插入。</p><p>Put提供了3种构造方式：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">Put</span><span class="params">(<span class="keyword">byte</span> [] row)</span></span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">Put</span><span class="params">(<span class="keyword">byte</span> [] row, RowLock rowLock)</span></span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">Put</span><span class="params">(Put putToCopy)</span></span></div></pre></td></tr></table></figure><p>Put常用的方法有：</p><p>add:增加一个Cell</p><p>setTimeStamp:指定所有cell默认的timestamp,如果一个Cell没有指定timestamp,就会用到这个值。如果没有调用，HBase会将当前时间作为未指定timestamp的cell的timestamp.</p><p>setWriteToWAL: WAL是Write Ahead Log的缩写，指的是HBase在插入操作前是否写Log。默认是打开，关掉会提高性能，但是如果系统出现故障(负责插入的Region Server挂掉)，数据可能会丢失。</p><p>另外HTable也有两个方法也会影响插入的性能</p><p>setAutoFlash: AutoFlush指的是在每次调用HBase的Put操作，是否提交到HBase Server。默认是true,每次会提交。如果此时是单条插入，就会有更多的IO,从而降低性能.</p><p>setWriteBufferSize: Write Buffer Size在AutoFlush为false的时候起作用，默认是2MB,也就是当插入数据超过2MB,就会自动提交到Server</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> cn.lesion.operateTable;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.HTable;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.HTableInterface;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.HTablePool;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Put;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"><span class="comment"> * Created in Intellij IDEA .</span></div><div class="line"><span class="comment"> * Author : 王乐.</span></div><div class="line"><span class="comment"> * Date : 2016.05.03.19.</span></div><div class="line"><span class="comment"> */</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Insert_Data</span> </span>&#123;</div><div class="line"></div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Configuration config = <span class="keyword">new</span> Configuration();</div><div class="line"></div><div class="line">    <span class="comment">//Loading configuration files on startup！</span></div><div class="line">    <span class="keyword">static</span> &#123;</div><div class="line"></div><div class="line">        <span class="comment">//add Create_Table config</span></div><div class="line">        config.addResource(<span class="string">"/conf/hbase-site.xml"</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line"></div><div class="line">        <span class="comment">// Create a new table named is 'abc'</span></div><div class="line">        insertData(<span class="string">"mytest"</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line"><span class="comment">     * According to tableName to insert data</span></div><div class="line"><span class="comment">     * <span class="doctag">@param</span> tableName</span></div><div class="line"><span class="comment">     */</span></div><div class="line">    <span class="function"><span class="keyword">private</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">insertData</span><span class="params">(String tableName)</span> </span>&#123;</div><div class="line">        System.out.println(<span class="string">"start insert data ......"</span>);</div><div class="line"></div><div class="line">        HTablePool pool = <span class="keyword">new</span> HTablePool(config, <span class="number">1000</span>);</div><div class="line"></div><div class="line">        <span class="comment">//Not Mandatory conversion to HTable  pool.getable return HTableInterface</span></div><div class="line">        HTableInterface table =  pool.getTable(tableName);</div><div class="line"></div><div class="line">        <span class="comment">// 一个PUT代表一行数据，再NEW一个PUT表示第二行数据,每行一个唯一的ROWKEY，此处rowkey为put构造方法中传入的值</span></div><div class="line">        <span class="comment">// one put == a row data, if new a 'put' it's a second row data</span></div><div class="line">        <span class="comment">// This rowkey is unique.</span></div><div class="line">        Put put = <span class="keyword">new</span> Put(<span class="string">"1"</span>.getBytes());</div><div class="line"></div><div class="line">        <span class="comment">// 本行数据的第一列</span></div><div class="line">        <span class="comment">// first data --&gt; first column</span></div><div class="line">        put.addColumn(<span class="string">"name"</span>.getBytes(), <span class="keyword">null</span>, <span class="string">"王乐"</span>.getBytes());</div><div class="line"></div><div class="line">        <span class="comment">// 本行数据的第三列</span></div><div class="line">        <span class="comment">// second column</span></div><div class="line">        put.addColumn(<span class="string">"age"</span>.getBytes(), <span class="keyword">null</span>, <span class="string">"19"</span>.getBytes());</div><div class="line"></div><div class="line">        <span class="comment">// 本行数据的第三列</span></div><div class="line">        <span class="comment">// third column</span></div><div class="line">        put.addColumn(<span class="string">"sex"</span>.getBytes(), <span class="keyword">null</span>, <span class="string">"男"</span>.getBytes());</div><div class="line"></div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            table.put(put);</div><div class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line">        System.out.println(<span class="string">"end insert data ......"</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure><h2 id="删除数据"><a href="#删除数据" class="headerlink" title="删除数据"></a>删除数据</h2><p>HTable 通过delete方法来删除数据。<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">delete</span><span class="params">(<span class="keyword">final</span> Delete delete)</span></span></div></pre></td></tr></table></figure></p><p>Delete构造方法有：</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">Delete</span><span class="params">(<span class="keyword">byte</span> [] row)</span></span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">Delete</span><span class="params">(<span class="keyword">byte</span> [] row, <span class="keyword">long</span> timestamp, RowLock rowLock)</span></span></div><div class="line"><span class="function"><span class="keyword">public</span> <span class="title">Delete</span><span class="params">(<span class="keyword">final</span> Delete d)</span></span></div></pre></td></tr></table></figure><p>Delete常用方法有</p><p>deleteFamily/deleteColumns:指定要删除的family或者column的数据。如果不调用任何这样的方法，将会删除整行。</p><p>注意：如果某个Cell的timestamp高于当前时间，这个Cell将不会被删除，仍然可以查出来。</p><p>示例：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> cn.lesion.operateTable;</div><div class="line"></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.Delete;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.hbase.client.HTable;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.IOException;</div><div class="line"><span class="keyword">import</span> java.util.ArrayList;</div><div class="line"><span class="keyword">import</span> java.util.List;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"><span class="comment"> * Created in Intellij IDEA .</span></div><div class="line"><span class="comment"> * Author : 王乐.</span></div><div class="line"><span class="comment"> * Date : 2016.05.03.21.</span></div><div class="line"><span class="comment"> */</span></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Delete_Data</span> </span>&#123;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Configuration config = <span class="keyword">new</span> Configuration();</div><div class="line"></div><div class="line">    <span class="comment">//Loading configuration files on startup！</span></div><div class="line">    <span class="keyword">static</span> &#123;</div><div class="line">        <span class="comment">//add Create_Table config</span></div><div class="line">        config.addResource(<span class="string">"/conf/hbase-site.xml"</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> </span>&#123;</div><div class="line">        deleteRow(<span class="string">"hbase_test"</span>,<span class="string">"1"</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line">    <span class="comment">/**</span></div><div class="line"><span class="comment">     * According to table's rowkey to delete data</span></div><div class="line"><span class="comment">     * <span class="doctag">@param</span> tablename</span></div><div class="line"><span class="comment">     * <span class="doctag">@param</span> rowkey</span></div><div class="line"><span class="comment">     */</span></div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">deleteRow</span><span class="params">(String tablename, String rowkey)</span>  </span>&#123;</div><div class="line">        <span class="keyword">try</span> &#123;</div><div class="line">            HTable table = <span class="keyword">new</span> HTable(config, tablename);</div><div class="line">            List&lt;Delete&gt; list = <span class="keyword">new</span> ArrayList&lt;Delete&gt;();</div><div class="line">            Delete d1 = <span class="keyword">new</span> Delete(rowkey.getBytes());</div><div class="line">            list.add(d1);</div><div class="line"></div><div class="line">            table.delete(list);</div><div class="line">            System.out.println(<span class="string">"Delete row success!"</span>);</div><div class="line"></div><div class="line">        &#125; <span class="keyword">catch</span> (IOException e) &#123;</div><div class="line">            e.printStackTrace();</div><div class="line">        &#125;</div><div class="line"></div><div class="line"></div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><h2 id="切分表"><a href="#切分表" class="headerlink" title="切分表"></a>切分表</h2><p>HBaseAdmin提供split方法来将table 进行split.</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">split</span><span class="params">(<span class="keyword">final</span> String tableNameOrRegionName)</span></span></div></pre></td></tr></table></figure><p>如果提供的tableName，那么会将table所有region进行split ;如果提供的region Name，那么只会split这个region.</p><p>由于split是一个异步操作，我们并不能确切的控制region的个数。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">split</span><span class="params">(String tableName,<span class="keyword">int</span> number,<span class="keyword">int</span> timeout)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line"></div><div class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Configuration config = <span class="keyword">new</span> Configuration();</div><div class="line"></div><div class="line">    <span class="comment">//Loading configuration files on startup！</span></div><div class="line">    <span class="keyword">static</span> &#123;</div><div class="line">        <span class="comment">//add Create_Table config</span></div><div class="line">        config.addResource(<span class="string">"/conf/hbase-site.xml"</span>);</div><div class="line">    &#125;</div><div class="line"></div><div class="line"></div><div class="line">    HBaseAdmin hAdmin = <span class="keyword">new</span> HBaseAdmin(config);</div><div class="line"></div><div class="line">    HTable hTable = <span class="keyword">new</span> HTable(config,tableName);</div><div class="line"></div><div class="line">    <span class="keyword">int</span> oldsize = <span class="number">0</span>;</div><div class="line"></div><div class="line">    t =  System.currentTimeMillis();</div><div class="line"></div><div class="line">    <span class="keyword">while</span>(<span class="keyword">true</span>)&#123;</div><div class="line"></div><div class="line">       <span class="keyword">int</span> size = hTable.getRegionsInfo().size();</div><div class="line"></div><div class="line">       logger.info(“the region number=”+size);</div><div class="line"></div><div class="line">       <span class="keyword">if</span>(size&gt;=number ) <span class="keyword">break</span>;</div><div class="line"></div><div class="line">       <span class="keyword">if</span>(size!=oldsize)&#123;</div><div class="line"></div><div class="line">           hAdmin.split(hTable.getTableName());</div><div class="line"></div><div class="line">           oldsize = size;</div><div class="line"></div><div class="line">       &#125;       <span class="keyword">else</span> <span class="keyword">if</span>(System.currentTimeMillis()-t&gt;timeout)&#123;</div><div class="line"></div><div class="line">           <span class="keyword">break</span>;</div><div class="line"></div><div class="line">       &#125;</div><div class="line"></div><div class="line">       Thread.sleep(<span class="number">1000</span>*<span class="number">10</span>);</div><div class="line"></div><div class="line">    &#125;</div><div class="line"></div><div class="line">&#125;</div></pre></td></tr></table></figure>]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;HBase的常用Java API
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
      <category term="HBase" scheme="http://gmle.github.io/categories/HBase/"/>
    
    
      <category term="Hadoop" scheme="http://gmle.github.io/tags/Hadoop/"/>
    
      <category term="HBase" scheme="http://gmle.github.io/tags/HBase/"/>
    
      <category term="Java" scheme="http://gmle.github.io/tags/Java/"/>
    
      <category term="API" scheme="http://gmle.github.io/tags/API/"/>
    
  </entry>
  
  <entry>
    <title>HBase的数据模型</title>
    <link href="http://gmle.github.io/2016/09/19/HBase%E7%9A%84%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B/"/>
    <id>http://gmle.github.io/2016/09/19/HBase的数据模型/</id>
    <published>2016-09-19T00:53:20.000Z</published>
    <updated>2017-05-03T06:38:01.000Z</updated>
    
    <content type="html"><![CDATA[<h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><p><a href="#介绍">介绍</a><br><a href="#概览">概览</a><br><a href="#行">行</a><br><a href="#列簇">列簇</a><br><a href="#时间戳">时间戳</a></p><p><a href="http://gmle.github.io/2016/05/05/HBase%E7%9A%84%E5%88%97%E6%97%8F/">此篇为参考文章</a></p><a id="more"></a><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><pre><code>HBase 的数据模型是继 Bigtable 数据模型的之后的克隆版，特别适用于密集的数据系统。也就是HBase是通过Google的BigTable演变而来</code></pre><h2 id="概览"><a href="#概览" class="headerlink" title="概览"></a>概览</h2><p>看简单点，HBase可以概括成一个Map</p><pre><code>&gt;Map&lt;byte[], Map&lt;byte[], Map&lt;byte[], Map&lt;Long, byte[]&gt;&gt;&gt;第一个Map是映射从 row keys 到 column families。第二个Map是映射从 column families 到他们的 column keys。第三个Map是映射从 column keys 到他们的 timestamps 。最后，最后的Map映射 timestamps 到一个单一的值。</code></pre><p>keys 一般为 字符串 strings， timestamps 是一个长整型 longs。<br>而值则为一个不解释的字节数组。<br>列的 keys 总在其 families 后面，表现如：family:key。因为一个 family 映射到另一个其他的map，这在理论上允许一个 family 包含无限个 column keys。<br>因此，为了获取一个值，用户需要使用三个 keys 来 get ：<br>    row key+column key+timestamp -&gt; value<br>    行键+列键+时间戳 -&gt; 值</p><h2 id="行"><a href="#行" class="headerlink" title="行"></a>行</h2><p>HBase 以数组格式来处理 row key，但 row key 本身是有字符串的形式表现。row key Map 一个特性就是以一个词典顺序来保存。例如，从1到100的数字，就是按照 1,10,100,11,12,13,14,15,16,17,18,19,2,20,21,…,9,91,92,93,94,95,96,97,98,99 这样的方式来保存。</p><p>要想以自然顺序来保存整型数，row keys 必须在左边以0填充。利用这一点，row key Map 的功能可以通过提供一个 scaner 来增强， scaner 带有一个 start row key 和 一个 stop row key。例如，如果 row keys 是日期格式 YYYYMMDD，获取 2008年7月整个月的内容，就是打开一个 scaner （20080700到20080800）。它并不关心指定的 row keys 存在与否，唯一要关心的，就是这个调用不会返回 stop row key，因此，stop row key 必须给 scaner 指定好。</p><h2 id="列簇"><a href="#列簇" class="headerlink" title="列簇"></a>列簇</h2><p>在 Hbase中，列成员重组具有同一性质的数据，并不限制数据类型。簇是表模式的一部分，为每行保存同种数据。与 froms rows to forws 不同的是 column keys 可以是稀少的。例如，row “20080702” 可以拥有自己的“info:”成员，该成员下有如下几个 column keys：<br>info:aaa<br>info:bbb<br>info:ccc<br>同样，row “20080703”仅有：<br>info:12342<br>在使用 column keys 的时候，开发者必须要非常小心。因为长度为0 的 key是允许的，这说明，在前面的例子中，数据可以被插入到 column key “info:” 中。我们强烈推荐，仅仅在没有其他的 keys 指定时使用空的 key。同样，由于一个成员中的数据是同一种类的，参考性能与时间戳 ，很多属性可以指定。</p><h2 id="时间戳"><a href="#时间戳" class="headerlink" title="时间戳"></a>时间戳</h2><p>根据成员的配置情况，HBase的值可以是以多版本的方式保存。缺省情况下，HBase将每个新值的时间戳设置为当前时间 milliseconds，并且当一个 cell 被请求时，返回最新的版本。开发者可以在插入数据时自定义时间戳，然后再通过指定这个时间戳来重新获取该值。<br>Family Attributes成员属性<br>可以为每一个簇指定下面的属性：</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h2&gt;&lt;p&gt;&lt;a href=&quot;#介绍&quot;&gt;介绍&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;#概览&quot;&gt;概览&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;#行&quot;&gt;行&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;#列簇&quot;&gt;列簇&lt;/a&gt;&lt;br&gt;&lt;a href=&quot;#时间戳&quot;&gt;时间戳&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://gmle.github.io/2016/05/05/HBase%E7%9A%84%E5%88%97%E6%97%8F/&quot;&gt;此篇为参考文章&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="HBase" scheme="http://gmle.github.io/categories/HBase/"/>
    
    
      <category term="Hadoop" scheme="http://gmle.github.io/tags/Hadoop/"/>
    
      <category term="HBase" scheme="http://gmle.github.io/tags/HBase/"/>
    
      <category term="数据模型" scheme="http://gmle.github.io/tags/%E6%95%B0%E6%8D%AE%E6%A8%A1%E5%9E%8B/"/>
    
  </entry>
  
  <entry>
    <title>hadoop常见面试题目（不定期更新）</title>
    <link href="http://gmle.github.io/2016/09/19/hadoop%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E7%9B%AE/"/>
    <id>http://gmle.github.io/2016/09/19/hadoop常见面试题目/</id>
    <published>2016-09-19T00:53:20.000Z</published>
    <updated>2017-05-03T06:38:19.000Z</updated>
    
    <content type="html"><![CDATA[<pre><code>整理一些面试题，以便与日后查看（不定期更新）</code></pre><h2 id="2016-04-21-–-更新"><a href="#2016-04-21-–-更新" class="headerlink" title="2016.04.21 – 更新"></a>2016.04.21 – 更新</h2><p>下面哪个程序负责 HDFS 数据存储？<br>    a)NameNode<br>    b)Jobtracker<br>    <font color="#ff0000">c)Datanode</font><br>    d)secondaryNameNode<br>    e)tasktracker</p><a id="more"></a><p>HDfS 中的 block 默认保存几份？<br>    <font color="#ff0000">a)3 份</font><br>    b)2 份<br>    c)1 份<br>    d)不确定</p><p>下列哪个程序通常与 NameNode 在一个节点启动？<br>    a)SecondaryNameNode<br>    b)DataNode<br>    c)TaskTracker<br>    <font color="#ff0000">d)Jobtracker</font></p><pre><code>&gt;此题分析：    hadoop的集群是基于master/slave模式，namenode和jobtracker属于master，datanode和tasktracker属于slave，master只有一个，而slave有多个SecondaryNameNode内存需求和NameNode在一个数量级上，所以通常secondary NameNode（运行在单独的物理机器上）和NameNode运行在不同的机器上。    JobTracker和TaskTracker；    JobTracker 对应于 NameNode；    TaskTracker 对应于 DataNode；    DataNode 和NameNode 是针对数据存放来而言的；    JobTracker和TaskTracker是对于MapReduce执行而言的。    mapreduce中几个主要概念，mapreduce整体上可以分为这么几条执行线索：obclient，JobTracker与TaskTracker。    1、JobClient会在用户端通过JobClient类将应用已经配置参数打包成jar文件存储到hdfs，并把路径提交到Jobtracker,然后由JobTracker创建每一个Task（即MapTask和ReduceTask）并将它们分发到各个TaskTracker服务中去执行。    2、JobTracker是一个master服务，软件启动之后JobTracker接收Job，负责调度Job的每一个子任务task运行于TaskTracker上，并监控它们，如果发现有失败的task就重新运行它。一般情况应该把JobTracker部署在单独的机器上。    3、TaskTracker是运行在多个节点上的slaver服务。TaskTracker主动与JobTracker通信，接收作业，并负责直接执行每一个任务。TaskTracker都需要运行在HDFS的DataNode上。</code></pre><p>Hadoop 作者 答案C Doug cutting<br>    a)Martin Fowler<br>    b)Kent Beck<br>    <font color="#ff0000">c)Doug cutting</font></p><p>下列哪项通常是集群的最主要瓶颈:<br>    a)CPU<br>    b)网络<br>    <font color="#ff0000">c)磁盘IO</font><br>    d)内存</p><pre><code>&gt;该题解析：    首先集群的目的是为了节省成本，用廉价的pc机，取代小型机及大型机。小型机和大型机有什么特点？    1.cpu处理能力强    2.内存够大    所以集群的瓶颈不可能是a和d    3.网络是一种稀缺资源，但是并不是瓶颈。    4.由于大数据面临海量数据，读写数据都需要io，然后还要冗余数据，hadoop一般备3份数据，所以IO就会打折扣。</code></pre><p>关于 SecondaryNameNode 哪项是正确的？<br>    a)它是 NameNode 的热备<br>    b)它对内存没有要求<br>    <font color="#ff0000">c)它的目的是帮助 NameNode 合并编辑日志，减少 NameNode 启动时间</font><br>    d)SecondaryNameNode 应与 NameNode 部署到一个节点。</p><p>下列哪项可以作为集群的管理？<br>    <font color="#ff0000">a)Puppet</font><br>    <font color="#ff0000">b)Pdsh</font><br>    c)Cloudera Manager<br>    <font color="#ff0000">d)Zookeeper</font></p><p>Cloudera 提供哪几种安装 CDH 的方法？<br>    <font color="#ff0000"><br>    a)Cloudera manager<br>    b)Tarball<br>    c)Yum<br>    d)Rpm<br>    </font></p><p>Ganglia 不仅可以进行监控，也可以进行告警。（ 正确）</p><pre><code>分析：此题的目的是考Ganglia的了解。严格意义上来讲是正确。ganglia作为一款最常用的Linux环境中的监控软件，它擅长的的是从节点中按照用户的需求以较低的代价采集数据。但是ganglia在预警以及发生事件后通知用户上并不擅长。最新的ganglia已经有了部分这方面的功能。但是更擅长做警告的还有Nagios。Nagios，就是一款精于预警、通知的软件。通过将Ganglia和Nagios组合起来，把Ganglia采集的数据作为Nagios的数据源，然后利用Nagios来发送预警通知，可以完美的实现一整套监控管理的系统。</code></pre><p>Block Size 是不可以修改的。（错误 ）</p><pre><code>分析：它是可以被修改的Hadoop的基础配置文件是hadoop-default.xml，默认建立一个Job的时候会建立Job的Config，Config首先读入hadoop-default.xml的配置，然后再读入hadoop-site.xml的配置（这个文件初始的时候配置为空），hadoop-site.xml中主要配置需要覆盖的hadoop-default.xml的系统级配置。</code></pre><p>Nagios 不可以监控 Hadoop 集群，因为它不提供 Hadoop 支持。（错误 ）</p><pre><code>分析：Nagios是集群监控工具，而且是云计算三大利器之一</code></pre><p>如果 NameNode 意外终止，SecondaryNameNode 会接替它使集群继续工作。（错误 ）</p><pre><code>分析：SecondaryNameNode是帮助恢复，而不是替代，如何恢复，可以查看</code></pre><p>Cloudera CDH 是需要付费使用的。（错误 ）</p><pre><code>分析：第一套付费产品是Cloudera Enterpris，Cloudera Enterprise在美国加州举行的 Hadoop 大会 (Hadoop Summit) 上公开，以若干私有管理、监控、运作工具加强 Hadoop 的功能。收费采取合约订购方式，价格随用的 Hadoop 叢集大小变动。</code></pre><p>Hadoop 是 Java 开发的，所以 MapReduce 只支持 Java 语言编写。（错误 ）</p><pre><code>分析：rhadoop是用R语言开发的，MapReduce是一个框架，可以理解是一种思想，可以使用其他语言开发。</code></pre><p>Hadoop 支持数据的随机读写。（错 ）</p><pre><code>分析：lucene是支持随机读写的，而hdfs只支持随机读。但是HBase可以来补救。HBase提供随机读写，来解决Hadoop不能处理的问题。HBase自底层设计开始即聚焦于各种可伸缩性问题：表可以很“高”，有数十亿个数据行；也可以很“宽”，有数百万个列；水平分区并在上千个普通商用机节点上自动复制。表的模式是物理存储的直接反映，使系统有可能提高高效的数据结构的序列化、存储和检索。</code></pre><p>NameNode 负责管理 metadata，client 端每次读写请求，它都会从磁盘中读取或则会写入 metadata 信息并反馈 client 端。（错误）</p><pre><code>此题分析：NameNode 不需要从磁盘读取 metadata，所有数据都在内存中，硬盘上的只是序列化的结果，只有每次 namenode 启动的时候才会读取。1）文件写入    Client向NameNode发起文件写入的请求。    NameNode根据文件大小和文件块配置情况，返回给Client它所管理部分DataNode的信息。    Client将文件划分为多个Block，根据DataNode的地址信息，按顺序写入到每一个DataNode块中。2）文件读取    Client向NameNode发起文件读取的请求。</code></pre><p>NameNode 本地磁盘保存了 Block 的位置信息。（ 个人认为正确，欢迎提出其它意见）</p><pre><code>分析：DataNode是文件存储的基本单元，它将Block存储在本地文件系统中，保存了Block的Meta-data，同时周期性地将所有存在的Block信息发送给NameNode。NameNode返回文件存储的DataNode的信息。Client读取文件信息。</code></pre><p>DataNode 通过长连接与 NameNode 保持通信。（ ）</p><pre><code>这个有分歧：具体正在找这方面的有利资料。下面提供资料可参考。首先明确一下概念：（1）.长连接    Client方与Server方先建立通讯连接，连接建立后不断开，然后再进行报文发送和接收。这种方式下由于通讯连接一直存在，此种方式常用于点对点通讯。（2）.短连接    Client方与Server每进行一次报文收发交易时才进行通讯连接，交易完毕后立即断开连接。此种方式常用于一点对多点通讯，比如多个Client连接一个Server.</code></pre><p>Hadoop 自身具有严格的权限管理和安全措施保障集群正常运行。（错误 ）</p><pre><code>hadoop只能阻止好人犯错，但是不能阻止坏人干坏事</code></pre><p>Slave 节点要存储数据，所以它的磁盘越大越好。（ 错误）</p><pre><code>分析：一旦Slave节点宕机，数据恢复是一个难题</code></pre><p>hadoop dfsadmin –report 命令用于检测 HDFS 损坏块。（错误 ）</p><p>Hadoop 默认调度器策略为 FIFO（正确 ）</p><p>集群内每个节点都应该配 RAID，这样避免单磁盘损坏，影响整个节点运行。（错误 ）</p><pre><code>分析：首先明白什么是RAID，可以参考百科磁盘阵列。这句话错误的地方在于太绝对，具体情况具体分析。题目不是重点，知识才是最重要的。因为hadoop本身就具有冗余能力，所以如果不是很严格不需要都配备RAID。具体参考第二题。</code></pre><p>因为 HDFS 有多个副本，所以 NameNode 是不存在单点问题的。（错误 ）</p><p>每个 map 槽就是一个线程。（错误 ）</p><pre><code>分析：首先我们知道什么是map 槽,map 槽-&gt;map slotmap slot 只是一个逻辑值 ( org.apache.hadoop.mapred.TaskTracker.TaskLauncher.numFreeSlots )，而不是对应着一个线程或者进程</code></pre><p>每个 map 槽就是一个线程。（错误 ）</p><pre><code>分析：首先我们知道什么是map 槽,map 槽-&gt;map slotmap slot 只是一个逻辑值 ( org.apache.hadoop.mapred.TaskTracker.TaskLauncher.numFreeSlots )，而不是对应着一个线程或者进程</code></pre><p>Mapreduce 的 input split 就是一个 block。（错误 ）</p><p> Hadoop 环境变量中的 HADOOP_HEAPSIZE 用于设置所有 Hadoop 守护线程的内存。它默认是 200 GB。（ 错误）</p><pre><code>hadoop为各个守护进程（namenode,secondarynamenode,jobtracker,datanode,tasktracker）统一分配的内存在hadoop-env.sh中设置，参数为HADOOP_HEAPSIZE，默认为1000M。</code></pre><p>NameNode 的 Web UI 端口是 50030，它通过 jetty 启动的 Web 服务。（错误 ）</p><p>DataNode 首次加入 cluster 的时候，如果 log 中报告不兼容文件版本，那需要 NameNode执行“Hadoop namenode -format”操作格式化磁盘。（错误 ）</p><pre><code>分析：首先明白介绍，什么ClusterIDClusterID添加了一个新的标识符ClusterID用于标识集群中所有的节点。当格式化一个Namenode，需要提供这个标识符或者自动生成。这个ID可以被用来格式化加入集群的其他Namenode。二次整理有的同学问题的重点不是上面分析内容：内容如下：这个报错是说明 DataNode 所装的Hadoop版本和其它节点不一致，应该检查DataNode的Hadoop版本</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;整理一些面试题，以便与日后查看（不定期更新）
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;2016-04-21-–-更新&quot;&gt;&lt;a href=&quot;#2016-04-21-–-更新&quot; class=&quot;headerlink&quot; title=&quot;2016.04.21 – 更新&quot;&gt;&lt;/a&gt;2016.04.21 – 更新&lt;/h2&gt;&lt;p&gt;下面哪个程序负责 HDFS 数据存储？&lt;br&gt;    a)NameNode&lt;br&gt;    b)Jobtracker&lt;br&gt;    &lt;font color=&quot;#ff0000&quot;&gt;c)Datanode&lt;/font&gt;&lt;br&gt;    d)secondaryNameNode&lt;br&gt;    e)tasktracker&lt;/p&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="http://gmle.github.io/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="http://gmle.github.io/tags/Hadoop/"/>
    
      <category term="面试" scheme="http://gmle.github.io/tags/%E9%9D%A2%E8%AF%95/"/>
    
  </entry>
  
  <entry>
    <title>HBase的配置(伪分布式)</title>
    <link href="http://gmle.github.io/2016/09/19/HBase%E7%9A%84%E9%85%8D%E7%BD%AE(%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F)/"/>
    <id>http://gmle.github.io/2016/09/19/HBase的配置(伪分布式)/</id>
    <published>2016-09-19T00:53:20.000Z</published>
    <updated>2017-05-03T06:38:09.000Z</updated>
    
    <content type="html"><![CDATA[<pre><code>HBase的CRUD</code></pre><p>###源码链接<br><a href="https://github.com/gmle/hbase" target="_blank" rel="external">https://github.com/gmle/hbase</a></p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;pre&gt;&lt;code&gt;HBase的CRUD
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;###源码链接&lt;br&gt;&lt;a href=&quot;https://github.com/gmle/hbase&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/g
      
    
    </summary>
    
      <category term="HBase" scheme="http://gmle.github.io/categories/HBase/"/>
    
    
      <category term="Hadoop" scheme="http://gmle.github.io/tags/Hadoop/"/>
    
      <category term="HBase" scheme="http://gmle.github.io/tags/HBase/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop_对HDFS中文件的操作</title>
    <link href="http://gmle.github.io/2016/09/19/HDFS%E7%9A%84%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C/"/>
    <id>http://gmle.github.io/2016/09/19/HDFS的文件操作/</id>
    <published>2016-09-19T00:53:20.000Z</published>
    <updated>2017-05-03T06:37:48.000Z</updated>
    
    <content type="html"><![CDATA[<pre><code>Hadoop没有当前目录的概念，当然也就没有 “cd” 命令HDFS文件操作的方法。</code></pre><h2 id="命令行方式"><a href="#命令行方式" class="headerlink" title="命令行方式"></a>命令行方式</h2><p>上一篇文章已经写到命令行方式操作HDFS，不再多说。<br><a href="http://gmle.github.io/2016/04/21/HSFS%E4%B8%AD%E6%96%87%E4%BB%B6%E7%9A%84%E4%B8%80%E4%BA%9B%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4/">进入传送门～</a></p><a id="more"></a><p>根据上一篇文章，写入两个文件：<br>Web查看文件的方式：<br>text1 : hello world.<br>text2 : hello hadoop.<br><img src="http://7xt0cb.com2.z0.glb.clouddn.com/文件访问方式.png" alt="Web查看文件的方式"></p><h2 id="Java-API操作HDFS"><a href="#Java-API操作HDFS" class="headerlink" title="Java API操作HDFS"></a>Java API操作HDFS</h2><p>新建一个Maven项目，不再细说<br><figure class="highlight xml"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div></pre></td><td class="code"><pre><div class="line">&lt;?xml version="1.0" encoding="UTF-8"?&gt;</div><div class="line"><span class="tag">&lt;<span class="name">project</span> <span class="attr">xmlns</span>=<span class="string">"http://maven.apache.org/POM/4.0.0"</span></span></div><div class="line"><span class="tag">         <span class="attr">xmlns:xsi</span>=<span class="string">"http://www.w3.org/2001/XMLSchema-instance"</span></span></div><div class="line"><span class="tag">         <span class="attr">xsi:schemaLocation</span>=<span class="string">"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd"</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">modelVersion</span>&gt;</span>4.0.0<span class="tag">&lt;/<span class="name">modelVersion</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>cn.lesion<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>bigData<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0-SNAPSHOT<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;<span class="name">dependencies</span>&gt;</span></div><div class="line"></div><div class="line"><span class="comment">&lt;!-- log4j日志包 --&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.logging.log4j<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>log4j-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.0-beta9<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div><div class="line"></div><div class="line"><span class="comment">&lt;!-- Hadoop开发包 --&gt;</span></div><div class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-common<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.6.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div><div class="line"></div><div class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.6.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div><div class="line"></div><div class="line">        <span class="tag">&lt;<span class="name">dependency</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></div><div class="line">            <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.2.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></div><div class="line">        <span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></div><div class="line"></div><div class="line">    <span class="tag">&lt;/<span class="name">dependencies</span>&gt;</span></div><div class="line"></div><div class="line"><span class="tag">&lt;/<span class="name">project</span>&gt;</span></div></pre></td></tr></table></figure></p><p>新建一个类，写入如下代码：<br><figure class="highlight java"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">package</span> cn.lesion.data;</div><div class="line"></div><div class="line"><span class="comment">/**</span></div><div class="line"><span class="comment"> * Created in Intellij IDEA .</span></div><div class="line"><span class="comment"> * Author : 王乐.</span></div><div class="line"><span class="comment"> * Date : 2016.04.19.20.</span></div><div class="line"><span class="comment"> *</span></div><div class="line"><span class="comment"> * 说明：读取hdfs中的文件内容</span></div><div class="line"><span class="comment"> */</span></div><div class="line"><span class="keyword">import</span> org.apache.hadoop.conf.Configuration;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.FileSystem;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.fs.Path;</div><div class="line"><span class="keyword">import</span> org.apache.hadoop.io.IOUtils;</div><div class="line"></div><div class="line"><span class="keyword">import</span> java.io.InputStream;</div><div class="line"><span class="keyword">import</span> java.net.URI;</div><div class="line"></div><div class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Hello</span> </span>&#123;</div><div class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</div><div class="line"></div><div class="line">        <span class="comment">//hdfs的地址</span></div><div class="line">        String uri = <span class="string">"hdfs://lele:9000/"</span>;</div><div class="line">        Configuration config = <span class="keyword">new</span> Configuration();</div><div class="line">        FileSystem fs = FileSystem.get(URI.create(uri), config);</div><div class="line"></div><div class="line">        <span class="comment">// 显示在hdfs的/tmp/input下指定文件的内容</span></div><div class="line">        InputStream is = fs.open(<span class="keyword">new</span> Path(<span class="string">"/user/test1.txt"</span>));</div><div class="line">        IOUtils.copyBytes(is, System.out, <span class="number">1024</span>, <span class="keyword">true</span>);</div><div class="line">    &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure></p><p>运行之后：<br>Hello<br><img src="http://7xt0cb.com2.z0.glb.clouddn.com/Hello-Hadoop.png" alt="美美的Hello"></p>]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;Hadoop没有当前目录的概念，当然也就没有 “cd” 命令
HDFS文件操作的方法。
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;命令行方式&quot;&gt;&lt;a href=&quot;#命令行方式&quot; class=&quot;headerlink&quot; title=&quot;命令行方式&quot;&gt;&lt;/a&gt;命令行方式&lt;/h2&gt;&lt;p&gt;上一篇文章已经写到命令行方式操作HDFS，不再多说。&lt;br&gt;&lt;a href=&quot;http://gmle.github.io/2016/04/21/HSFS%E4%B8%AD%E6%96%87%E4%BB%B6%E7%9A%84%E4%B8%80%E4%BA%9B%E6%93%8D%E4%BD%9C%E5%91%BD%E4%BB%A4/&quot;&gt;进入传送门～&lt;/a&gt;&lt;/p&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="http://gmle.github.io/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="http://gmle.github.io/tags/Hadoop/"/>
    
      <category term="HDFS" scheme="http://gmle.github.io/tags/HDFS/"/>
    
      <category term="HDFS操作" scheme="http://gmle.github.io/tags/HDFS%E6%93%8D%E4%BD%9C/"/>
    
  </entry>
  
  <entry>
    <title>Hadoop_HDFS底层架构</title>
    <link href="http://gmle.github.io/2016/09/19/%E5%AF%B9HDFS%E7%9A%84%E4%B8%80%E4%BA%9B%E8%AE%A4%E8%AF%86/"/>
    <id>http://gmle.github.io/2016/09/19/对HDFS的一些认识/</id>
    <published>2016-09-19T00:53:20.000Z</published>
    <updated>2017-05-03T06:38:42.000Z</updated>
    
    <content type="html"><![CDATA[<pre><code>这是我对HDFS的认知与了解，并结合网上查阅的资料进行的整合。</code></pre><h2 id="HDFS设计基础与目标"><a href="#HDFS设计基础与目标" class="headerlink" title="HDFS设计基础与目标"></a>HDFS设计基础与目标</h2><ul><li>硬件错误是常态，因此需要冗余。<ul><li>错误检测和快速、自动的恢复是HDFS最核心的架构目标</li></ul></li><li>小文件不适合存储，适合存储超大文件</li><li>流式数据访问</li></ul><a id="more"></a><ul><li>流式数据访问，即数据劈来给你读取而非随机读写，Hadoop需要的是数据分析而不是事务处理</li><li>大规模数据集</li><li>简单一致性模型，为了降低系统复杂度，对文件采用一次写多次读的理念：文件一经写入，关闭，再也不能修改。</li><li>程序采用 “数据就近” 原则分配节点执行。</li></ul><h3 id="HDFS的底层架构"><a href="#HDFS的底层架构" class="headerlink" title="HDFS的底层架构"></a>HDFS的底层架构</h3><h4 id="分布式文件系统"><a href="#分布式文件系统" class="headerlink" title="分布式文件系统"></a>分布式文件系统</h4><p>  优点：</p><pre><code>- 传统文件系统最大问题是容量和吞吐来那个的限制- 多用户多应用的并行读写是分布式文件系统产生的根源- 扩充存储空间的成本低廉    - 物理层存储的分布式    - 基于科户籍/服务器模式    - 通常情况下基于操作系统的本地文件系统</code></pre><h3 id="HDFS体系结构"><a href="#HDFS体系结构" class="headerlink" title="HDFS体系结构"></a>HDFS体系结构</h3><p><img src="http://7xt0cb.com1.z0.glb.clouddn.com/Hadoop%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84.png" alt="Hadoop体系结构图"></p><ul><li>NameNode<ul><li>管理文件系统的命名空间</li><li>记录每个文件数据快再各个DataNode上的文职和副本信息</li><li>协调客户端对文件的访问</li><li>协调客户端对文件的访问</li><li>记录命名空间内的改动或空间本身属性的改动</li><li>NameNode使用事务日志记录HDFS元数据的变化，使用映像文件存储文件系统的命名空间，包括文件映射，文件属性等</li></ul></li><li>DataNode<ul><li>负责所在物理节点的存储管理</li><li>一次写入，多次读取（不能修改）</li><li>文件由数据块组成，典型块的大小  0-1.0之间版本大小-&gt; 64M  1-2.x 大小为 128M</li><li>数据块尽量散布到各个节点内</li></ul></li><li>事务日志</li><li>映像文件</li><li>SecondaryNameNode</li></ul><h3 id="HDFS的高可用性"><a href="#HDFS的高可用性" class="headerlink" title="HDFS的高可用性"></a>HDFS的高可用性</h3><ul><li>HDFS集群中NameNode存在单点故障。<ul><li>躲雨只有一个NameNode的集群，如果NameNode及其出现意外downtime，那么整个集群将无法使用，知道NameNode重新启动</li></ul></li></ul>]]></content>
    
    <summary type="html">
    
      &lt;pre&gt;&lt;code&gt;这是我对HDFS的认知与了解，并结合网上查阅的资料进行的整合。
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&quot;HDFS设计基础与目标&quot;&gt;&lt;a href=&quot;#HDFS设计基础与目标&quot; class=&quot;headerlink&quot; title=&quot;HDFS设计基础与目标&quot;&gt;&lt;/a&gt;HDFS设计基础与目标&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;硬件错误是常态，因此需要冗余。&lt;ul&gt;
&lt;li&gt;错误检测和快速、自动的恢复是HDFS最核心的架构目标&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;小文件不适合存储，适合存储超大文件&lt;/li&gt;
&lt;li&gt;流式数据访问&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
      <category term="Hadoop" scheme="http://gmle.github.io/categories/Hadoop/"/>
    
    
      <category term="Hadoop" scheme="http://gmle.github.io/tags/Hadoop/"/>
    
      <category term="HDFS" scheme="http://gmle.github.io/tags/HDFS/"/>
    
  </entry>
  
</feed>
